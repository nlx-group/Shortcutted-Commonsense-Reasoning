{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import sys\n",
    "from itertools import permutations, chain\n",
    "from functools import partial\n",
    "import json\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import logging\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"datasets.builder\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")\n",
    "\n",
    "def tokenize(s):\n",
    "    return [\n",
    "        word.lower() for word in\n",
    "        nltk.word_tokenize(s)\n",
    "        if word.isalnum()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_gram_value(examples, example_to_tokens_f):\n",
    "    n_tokens = []\n",
    "    for _, example in tqdm(enumerate(examples), total=len(examples)):\n",
    "        tokens = example_to_tokens_f(example)\n",
    "        for ex in tokens:\n",
    "            n_tokens.append(len(ex))\n",
    "    return min(max(np.percentile(n_tokens, 5, interpolation=\"linear\"), 8), 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_ngrams(n, examples, example_to_tokens_f):\n",
    "    n_grams = set()\n",
    "    # Sacrifice memory for speed\n",
    "    # I could use OrderedSet but its 5x slower to search in!\n",
    "    ngrams_in_example = dict()\n",
    "    example_in_ngram = dict()\n",
    "    for idx, example in tqdm(enumerate(examples), total=len(examples)):\n",
    "        for tokens in example_to_tokens_f(example):\n",
    "            for ngram in ngrams(tokens, n):\n",
    "                if ngram not in example_in_ngram:\n",
    "                    example_in_ngram[ngram] = []\n",
    "                if idx not in example_in_ngram:\n",
    "                    ngrams_in_example[idx] = []\n",
    "                ngrams_in_example[idx].append(ngram)\n",
    "                if idx not in example_in_ngram[ngram]:\n",
    "                    example_in_ngram[ngram].append(idx)\n",
    "                n_grams.add(ngram)\n",
    "    return n_grams, ngrams_in_example, example_in_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arc_example_to_tokens(example):\n",
    "    tokens = []\n",
    "    for i in range(len(example[\"choices\"][\"label\"])):\n",
    "        tokens.append(tokenize(example[\"question\"]) + tokenize(example[\"choices\"][\"text\"][i]))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csqa_example_to_tokens(example):\n",
    "    tokens = []\n",
    "    for i in range(len(example[\"choices\"][\"label\"])):\n",
    "        tokens.append(tokenize(example[\"question\"]) + tokenize(example[\"choices\"][\"text\"][i]))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arct_example_to_tokens(example):\n",
    "    tokens = []\n",
    "    for i in range(2):\n",
    "        for p_one, p_two, p_three in permutations([\"reason\", \"claim\", f\"warrant{i}\"]):\n",
    "            tokens.append(tokenize(example[p_one]) + tokenize(example[p_two]) + tokenize(example[p_three]))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piqa_example_to_tokens(example):\n",
    "    tokens = []\n",
    "    for i in range(1, 3):\n",
    "        tokens.append(tokenize(example[\"goal\"]) + tokenize(example[f\"sol{i}\"]))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5760a250ce74479888a9f7cc64a3dc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N value: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23c376a7bb547fda7fc0cfb3e66b254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# ngrams in arc: 35453\n"
     ]
    }
   ],
   "source": [
    "arc = load_dataset(\"ai2_arc\", \"ARC-Challenge\")\n",
    "arc_n_gram = int(get_n_gram_value(arc[\"test\"], arc_example_to_tokens))\n",
    "print(f\"N value: {arc_n_gram}\")\n",
    "arc_ngrams, arc_ngram_ex, arc_ex_ngram = dataset_to_ngrams(arc_n_gram, arc[\"test\"], arc_example_to_tokens)\n",
    "print(f\"# ngrams in arc: {len(arc_ngrams)}\")\n",
    "arc_dirty_hits = pd.concat([\n",
    "    pd.DataFrame(data={\"example_id\": [i], \"BookCorpus_hits\": [0], \"ccnews_hits\": [0], \"openwebtext_hits\": [0], \"stories_hits\": [0], \"wikipedia_hits\": [0], \"atomic_hits\": [0]})\n",
    "    for i in range(len(arc[\"test\"]))\n",
    "]).reset_index(drop=True)\n",
    "arc_df_and_lookup = (arc_dirty_hits, arc_ex_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94944334add64c21be2c67b8afe3bbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N value: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bde7f94183d4bdba7ffd799dcf2a2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# ngrams in csqa: 16243\n"
     ]
    }
   ],
   "source": [
    "csqa = load_dataset(\"commonsense_qa\")\n",
    "csqa_n_gram = int(get_n_gram_value(csqa[\"validation\"], csqa_example_to_tokens))\n",
    "print(f\"N value: {csqa_n_gram}\")\n",
    "csqa_ngrams, csqa_ngram_ex, csqa_ex_ngram = dataset_to_ngrams(csqa_n_gram, csqa[\"validation\"], csqa_example_to_tokens)\n",
    "print(f\"# ngrams in csqa: {len(csqa_ngrams)}\")\n",
    "csqa_dirty_hits = pd.concat([\n",
    "    pd.DataFrame(data={\"example_id\": [i], \"BookCorpus_hits\": [0], \"ccnews_hits\": [0], \"openwebtext_hits\": [0], \"stories_hits\": [0], \"wikipedia_hits\": [0], \"atomic_hits\": [0]})\n",
    "    for i in range(len(csqa[\"validation\"]))\n",
    "]).reset_index(drop=True)\n",
    "csqa_df_and_lookup = (csqa_dirty_hits, csqa_ex_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa209693a50b4aab8b0ad6b9afbe9856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=888.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N value: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f221f7d274477fbcfa6d87f642fad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=888.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# ngrams in arct: 46341\n"
     ]
    }
   ],
   "source": [
    "arct = list(map(lambda x: x[1], pd.read_csv(os.path.join(\"..\", \"data\", \"arct\", \"test.csv\"), sep=\"\\t\").iterrows()))\n",
    "arct_n_gram = int(get_n_gram_value(arct, arct_example_to_tokens))\n",
    "print(f\"N value: {arct_n_gram}\")\n",
    "arct_ngrams, arct_ngram_ex, arct_ex_ngram = dataset_to_ngrams(arct_n_gram, arct, arct_example_to_tokens)\n",
    "print(f\"# ngrams in arct: {len(arct_ngrams)}\")\n",
    "arct_dirty_hits = pd.concat([\n",
    "    pd.DataFrame(data={\"example_id\": [i], \"BookCorpus_hits\": [0], \"ccnews_hits\": [0], \"openwebtext_hits\": [0], \"stories_hits\": [0], \"wikipedia_hits\": [0], \"atomic_hits\": [0]})\n",
    "    for i in range(len(arct))\n",
    "]).reset_index(drop=True)\n",
    "arct_df_and_lookup = (arct_dirty_hits, arct_ex_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61494c15c81d4ef8858df6c50b06ae08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1838.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N value: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cea46b272ba4df1b111637dc2678613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1838.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# ngrams in piqa: 47257\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(\"..\", \"data\", \"PIQA\", \"valid.jsonl\") as fr:\n",
    "    piqa = list(map(lambda line: json.loads(line), fr))\n",
    "piqa_n_gram = int(get_n_gram_value(piqa, piqa_example_to_tokens))\n",
    "print(f\"N value: {piqa_n_gram}\")\n",
    "piqa_ngrams, piqa_ngram_ex, piqa_ex_ngram = dataset_to_ngrams(piqa_n_gram, piqa, piqa_example_to_tokens)\n",
    "print(f\"# ngrams in piqa: {len(piqa_ngrams)}\")\n",
    "piqa_dirty_hits = pd.concat([\n",
    "    pd.DataFrame(data={\"example_id\": [i], \"BookCorpus_hits\": [0], \"ccnews_hits\": [0], \"openwebtext_hits\": [0], \"stories_hits\": [0], \"wikipedia_hits\": [0], \"atomic_hits\": [0]})\n",
    "    for i in range(len(piqa))\n",
    "]).reset_index(drop=True)\n",
    "piqa_df_and_lookup = (piqa_dirty_hits, piqa_ex_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145294"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_ngrams = arc_ngrams.union(csqa_ngrams).union(arct_ngrams).union(piqa_ngrams)\n",
    "len(testset_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 10, 13]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = list(set([arc_n_gram, csqa_n_gram, arct_n_gram, piqa_n_gram]))\n",
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_df_and_lookup = [\n",
    "    arc_df_and_lookup,\n",
    "    csqa_df_and_lookup,\n",
    "    arct_df_and_lookup,\n",
    "    piqa_df_and_lookup,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenWebText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"openwebtext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contamination_openwebtext(args, testset_ngrams=None, ns=None):\n",
    "    dirty_hits = {ngram: 0 for ngram in testset_ngrams}\n",
    "    ds = load_dataset(\"openwebtext\")\n",
    "    idxs, n_worker = args\n",
    "    # cos jupyterlab is dumb\n",
    "    print(' ', end='', flush=True)\n",
    "    for idx, ds_idx in tqdm(enumerate(idxs), total=len(idxs), position=n_worker+1, leave=False, desc=f\"Worker #{n_worker}\"):\n",
    "        text = tokenize(ds[\"train\"][int(ds_idx)][\"text\"])\n",
    "        for n in ns:\n",
    "            for ngram in ngrams(text, n):\n",
    "                if ngram in testset_ngrams:\n",
    "                    dirty_hits[ngram] += 1\n",
    "    print(\"Concating now\")\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(data={\"ngram\": [k], \"dirty_count\": [v]})\n",
    "            for k, v in dirty_hits.items()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 else race condition\n",
    "n_cores = 32 #cpu_count()\n",
    "pool = Pool()\n",
    "results_df = pd.concat(\n",
    "    tqdm(\n",
    "        pool.imap_unordered(\n",
    "            partial(\n",
    "                check_contamination_openwebtext, testset_ngrams=testset_ngrams, ns=ns\n",
    "            ),\n",
    "            zip(np.array_split(range(len(ds[\"train\"])), n_cores), list(range(n_cores)))\n",
    "        ),\n",
    "        total=n_cores,\n",
    "        leave=False,\n",
    "        position=0,\n",
    "        desc=\"Global progress\"\n",
    "    ),\n",
    "    ignore_index=True,\n",
    ")\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = results_df.groupby([\"ngram\"], as_index=False).agg({\"dirty_count\": \"sum\"})\n",
    "agg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df.to_csv(\"contamination_openwebtext.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = pd.read_csv(\"contamination_openwebtext.tsv\", sep=\"\\t\")\n",
    "agg_results_df[\"ngram\"] = agg_results_df[\"ngram\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>(oil, in, a, large, skillet, over, medium, heat)</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59383</th>\n",
       "      <td>(in, a, large, skillet, over, medium, heat, add)</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123931</th>\n",
       "      <td>(to, a, boil, then, reduce, the, heat, to)</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21926</th>\n",
       "      <td>(bring, to, a, boil, then, reduce, the, heat)</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85566</th>\n",
       "      <td>(olive, oil, in, a, large, skillet, over, medium)</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48472</th>\n",
       "      <td>(furniture, and, put, every, piece, together, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48471</th>\n",
       "      <td>(fur, would, be, best, fit, for, which, type, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48470</th>\n",
       "      <td>(fur, what, have, you, done, lots, of, attention)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48469</th>\n",
       "      <td>(fur, this, is, an, example, of, an, animal, r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145293</th>\n",
       "      <td>(zygote, with, a, woman, with, an, rr, allele,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ngram  dirty_count\n",
       "85437    (oil, in, a, large, skillet, over, medium, heat)           69\n",
       "59383    (in, a, large, skillet, over, medium, heat, add)           62\n",
       "123931         (to, a, boil, then, reduce, the, heat, to)           46\n",
       "21926       (bring, to, a, boil, then, reduce, the, heat)           39\n",
       "85566   (olive, oil, in, a, large, skillet, over, medium)           37\n",
       "...                                                   ...          ...\n",
       "48472   (furniture, and, put, every, piece, together, ...            0\n",
       "48471   (fur, would, be, best, fit, for, which, type, ...            0\n",
       "48470   (fur, what, have, you, done, lots, of, attention)            0\n",
       "48469   (fur, this, is, an, example, of, an, animal, r...            0\n",
       "145293  (zygote, with, a, woman, with, an, rr, allele,...            0\n",
       "\n",
       "[145294 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_df.sort_values(\"dirty_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(agg_results_df[\"dirty_count\"] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10, to, 15, minutes, to, stiffen, it, up)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(20, feet, away, for, 20, seconds, every, 20)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(20, minutes, or, until, a, toothpick, inserte...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(4, hours, or, overnight, when, ready, to, serve)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(a, boil, reduce, the, heat, to, a, simmer)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>(you, can, use, a, hot, glue, gun, to)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>(you, can, use, a, pair, of, pliers, to)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>(you, want, to, learn, about, the, world, and)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>(your, computer, when, you, are, not, using, it)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>(your, kitchen, sink, then, peel, potatoes, sl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ngram  dirty_count\n",
       "0           (10, to, 15, minutes, to, stiffen, it, up)            1\n",
       "1        (20, feet, away, for, 20, seconds, every, 20)            3\n",
       "2    (20, minutes, or, until, a, toothpick, inserte...            9\n",
       "3    (4, hours, or, overnight, when, ready, to, serve)            2\n",
       "4          (a, boil, reduce, the, heat, to, a, simmer)            4\n",
       "..                                                 ...          ...\n",
       "350             (you, can, use, a, hot, glue, gun, to)            3\n",
       "351           (you, can, use, a, pair, of, pliers, to)            1\n",
       "352     (you, want, to, learn, about, the, world, and)            1\n",
       "353   (your, computer, when, you, are, not, using, it)            1\n",
       "354  (your, kitchen, sink, then, peel, potatoes, sl...            1\n",
       "\n",
       "[355 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openwebtext_dirty_hits = agg_results_df[agg_results_df[\"dirty_count\"] > 0].reset_index(drop=True)\n",
    "openwebtext_dirty_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c215639609542a8aa5388ce4fd48c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=355.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(openwebtext_dirty_hits.iterrows(), total=len(openwebtext_dirty_hits)):\n",
    "    for dirty_hit_df, lookup in tasks_df_and_lookup:\n",
    "        if row.ngram in lookup:\n",
    "            for ex_num in lookup[row.ngram]:\n",
    "                dirty_hit_df.at[ex_num, \"openwebtext_hits\"] += row.dirty_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics after openwebtext\n",
      "ARC: 10/1172 (0.8532423208191127%)\n",
      "CSQA: 32/1221 (2.620802620802621%)\n",
      "ARCT: 0/888 (0.0%)\n",
      "PIQA: 124/1838 (6.746463547334058%)\n"
     ]
    }
   ],
   "source": [
    "arc_ex_dirty_num = (\n",
    "    (arc_dirty_hits[\"BookCorpus_hits\"] > 0) | (arc_dirty_hits[\"ccnews_hits\"] > 0) | (arc_dirty_hits[\"openwebtext_hits\"] > 0) | (arc_dirty_hits[\"stories_hits\"] > 0) | (arc_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "csqa_ex_dirty_num = (\n",
    "    (csqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (csqa_dirty_hits[\"ccnews_hits\"] > 0) | (csqa_dirty_hits[\"openwebtext_hits\"] > 0) | (csqa_dirty_hits[\"stories_hits\"] > 0) | (csqa_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "arct_ex_dirty_num = (\n",
    "    (arct_dirty_hits[\"BookCorpus_hits\"] > 0) | (arct_dirty_hits[\"ccnews_hits\"] > 0) | (arct_dirty_hits[\"openwebtext_hits\"] > 0) | (arct_dirty_hits[\"stories_hits\"] > 0) | (arct_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "piqa_ex_dirty_num = (\n",
    "    (piqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (piqa_dirty_hits[\"ccnews_hits\"] > 0) | (piqa_dirty_hits[\"openwebtext_hits\"] > 0) | (piqa_dirty_hits[\"stories_hits\"] > 0) | (piqa_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "\n",
    "print(\"Statistics after openwebtext\")\n",
    "print(f\"ARC: {arc_ex_dirty_num}/{len(arc_dirty_hits)} ({(arc_ex_dirty_num/len(arc_dirty_hits)) * 100}%)\")\n",
    "print(f\"CSQA: {csqa_ex_dirty_num}/{len(csqa_dirty_hits)} ({(csqa_ex_dirty_num/len(csqa_dirty_hits)) * 100}%)\")\n",
    "print(f\"ARCT: {arct_ex_dirty_num}/{len(arct_dirty_hits)} ({(arct_ex_dirty_num/len(arct_dirty_hits)) * 100}%)\")\n",
    "print(f\"PIQA: {piqa_ex_dirty_num}/{len(piqa_dirty_hits)} ({(piqa_ex_dirty_num/len(piqa_dirty_hits)) * 100}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded from https://drive.google.com/drive/u/1/folders/1yZzwaV8LO1hK8ChIm0sxazXF8BSIZ683\n",
    "PATH_TO_STORIES = \"\"\n",
    "stories_files = glob(PATH_TO_STORIES)\n",
    "len(stories_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contamination_stories(args, testset_ngrams=None, ns=None):\n",
    "    dirty_hits = {ngram: 0 for ngram in testset_ngrams}\n",
    "    files, n_worker = args\n",
    "    # cos jupyterlab is dumb\n",
    "    print(' ', end='', flush=True)\n",
    "    for idx, file_name in tqdm(enumerate(files), total=len(files), position=n_worker+1, leave=False, desc=f\"Worker #{n_worker}\"):\n",
    "        with open(file_name, \"rt\") as f:\n",
    "            text = tokenize(f.read())\n",
    "        for n in ns:\n",
    "            for ngram in ngrams(text, n):\n",
    "                if ngram in testset_ngrams:\n",
    "                    dirty_hits[ngram] += 1\n",
    "    print(\"Concating now\")\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(data={\"ngram\": [k], \"dirty_count\": [v]})\n",
    "            for k, v in dirty_hits.items()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 56\n",
    "pool = Pool()\n",
    "results_df = pd.concat(\n",
    "    tqdm(\n",
    "        pool.imap_unordered(\n",
    "            partial(\n",
    "                check_contamination_stories, testset_ngrams=testset_ngrams, ns=ns\n",
    "            ),\n",
    "            zip(np.array_split(stories_files, n_cores), list(range(n_cores))),\n",
    "        ),\n",
    "        total=n_cores,\n",
    "        leave=False,\n",
    "        position=0,\n",
    "        desc=\"Global progress\",\n",
    "    ),\n",
    "    ignore_index=True,\n",
    ")\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = results_df.groupby([\"ngram\"], as_index=False).agg({\"dirty_count\": \"sum\"})\n",
    "agg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df.to_csv(\"contamination_stories.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = pd.read_csv(\"contamination_stories.tsv\", sep=\"\\t\")\n",
    "agg_results_df[\"ngram\"] = agg_results_df[\"ngram\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134319</th>\n",
       "      <td>(was, going, to, grow, up, to, be, a)</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>(oil, in, a, large, skillet, over, medium, heat)</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59383</th>\n",
       "      <td>(in, a, large, skillet, over, medium, heat, add)</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136406</th>\n",
       "      <td>(what, do, you, do, when, you, need, to)</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85566</th>\n",
       "      <td>(olive, oil, in, a, large, skillet, over, medium)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48462</th>\n",
       "      <td>(fur, of, a, dog, with, light, colored, fur)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48461</th>\n",
       "      <td>(fur, is, dominant, to, white, fur, in, guinea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48460</th>\n",
       "      <td>(fur, in, guinea, pigs, if, two, black, guinea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48459</th>\n",
       "      <td>(funnel, that, you, washed, out, til, you, need)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145293</th>\n",
       "      <td>(zygote, with, a, woman, with, an, rr, allele,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ngram  dirty_count\n",
       "134319              (was, going, to, grow, up, to, be, a)           67\n",
       "85437    (oil, in, a, large, skillet, over, medium, heat)           58\n",
       "59383    (in, a, large, skillet, over, medium, heat, add)           52\n",
       "136406           (what, do, you, do, when, you, need, to)           45\n",
       "85566   (olive, oil, in, a, large, skillet, over, medium)           40\n",
       "...                                                   ...          ...\n",
       "48462        (fur, of, a, dog, with, light, colored, fur)            0\n",
       "48461   (fur, is, dominant, to, white, fur, in, guinea...            0\n",
       "48460   (fur, in, guinea, pigs, if, two, black, guinea...            0\n",
       "48459    (funnel, that, you, washed, out, til, you, need)            0\n",
       "145293  (zygote, with, a, woman, with, an, rr, allele,...            0\n",
       "\n",
       "[145294 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_df.sort_values(\"dirty_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(agg_results_df[\"dirty_count\"] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(15, to, 20, minutes, or, until, a, toothpick)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2, to, 3, minutes, until, soft, add, the)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(20, minutes, or, until, a, toothpick, inserte...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(4, hours, or, overnight, when, ready, to, serve)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(5, minutes, stirring, constantly, remove, fro...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>(you, have, to, do, in, order, to, finish)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>(you, have, to, read, a, book, that, is)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>(you, need, a, map, to, find, your, way)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>(you, want, to, kill, someone, you, can, do)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>(your, tongue, in, the, roof, of, your, mouth)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ngram  dirty_count\n",
       "0       (15, to, 20, minutes, or, until, a, toothpick)            3\n",
       "1           (2, to, 3, minutes, until, soft, add, the)            1\n",
       "2    (20, minutes, or, until, a, toothpick, inserte...           20\n",
       "3    (4, hours, or, overnight, when, ready, to, serve)            1\n",
       "4    (5, minutes, stirring, constantly, remove, fro...            5\n",
       "..                                                 ...          ...\n",
       "292         (you, have, to, do, in, order, to, finish)            1\n",
       "293           (you, have, to, read, a, book, that, is)            1\n",
       "294           (you, need, a, map, to, find, your, way)            5\n",
       "295       (you, want, to, kill, someone, you, can, do)            1\n",
       "296     (your, tongue, in, the, roof, of, your, mouth)            1\n",
       "\n",
       "[297 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_dirty_hits = agg_results_df[agg_results_df[\"dirty_count\"] > 0].reset_index(drop=True)\n",
    "stories_dirty_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938e4c573715427e9501e297f3c18664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=297.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(stories_dirty_hits.iterrows(), total=len(stories_dirty_hits)):\n",
    "    for dirty_hit_df, lookup in tasks_df_and_lookup:\n",
    "        if row.ngram in lookup:\n",
    "            for ex_num in lookup[row.ngram]:\n",
    "                dirty_hit_df.at[ex_num, \"stories_hits\"] += row.dirty_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics after stories\n",
      "ARC: 10/1172 (0.8532423208191127%)\n",
      "CSQA: 53/1221 (4.340704340704341%)\n",
      "ARCT: 0/888 (0.0%)\n",
      "PIQA: 173/1838 (9.412404787812841%)\n"
     ]
    }
   ],
   "source": [
    "arc_ex_dirty_num = (\n",
    "    (arc_dirty_hits[\"BookCorpus_hits\"] > 0) | (arc_dirty_hits[\"ccnews_hits\"] > 0) | (arc_dirty_hits[\"openwebtext_hits\"] > 0) | (arc_dirty_hits[\"stories_hits\"] > 0) | (arc_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "csqa_ex_dirty_num = (\n",
    "    (csqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (csqa_dirty_hits[\"ccnews_hits\"] > 0) | (csqa_dirty_hits[\"openwebtext_hits\"] > 0) | (csqa_dirty_hits[\"stories_hits\"] > 0) | (csqa_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "arct_ex_dirty_num = (\n",
    "    (arct_dirty_hits[\"BookCorpus_hits\"] > 0) | (arct_dirty_hits[\"ccnews_hits\"] > 0) | (arct_dirty_hits[\"openwebtext_hits\"] > 0) | (arct_dirty_hits[\"stories_hits\"] > 0) | (arct_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "piqa_ex_dirty_num = (\n",
    "    (piqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (piqa_dirty_hits[\"ccnews_hits\"] > 0) | (piqa_dirty_hits[\"openwebtext_hits\"] > 0) | (piqa_dirty_hits[\"stories_hits\"] > 0) | (piqa_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "\n",
    "print(\"Statistics after stories\")\n",
    "print(f\"ARC: {arc_ex_dirty_num}/{len(arc_dirty_hits)} ({(arc_ex_dirty_num/len(arc_dirty_hits)) * 100}%)\")\n",
    "print(f\"CSQA: {csqa_ex_dirty_num}/{len(csqa_dirty_hits)} ({(csqa_ex_dirty_num/len(csqa_dirty_hits)) * 100}%)\")\n",
    "print(f\"ARCT: {arct_ex_dirty_num}/{len(arct_dirty_hits)} ({(arct_ex_dirty_num/len(arct_dirty_hits)) * 100}%)\")\n",
    "print(f\"PIQA: {piqa_ex_dirty_num}/{len(piqa_dirty_hits)} ({(piqa_ex_dirty_num/len(piqa_dirty_hits)) * 100}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BookCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded from https://the-eye.eu/public/AI/pile_preliminary_components/books1.tar.gz\n",
    "\n",
    "PATH_TO_BOOKS = \"\"\n",
    "book_files = glob(PATH_TO_BOOKS)\n",
    "len(book_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contamination_books(args, testset_ngrams=None, ns=None):\n",
    "    dirty_hits = {ngram: 0 for ngram in testset_ngrams}\n",
    "    files, n_worker = args\n",
    "    # cos jupyterlab is dumb\n",
    "    print(' ', end='', flush=True)\n",
    "    for idx, file_name in tqdm(enumerate(files), total=len(files), position=n_worker+1, leave=False, desc=f\"Worker #{n_worker}\"):\n",
    "        with open(file_name, \"rt\") as f:\n",
    "            text = tokenize(f.read())\n",
    "        for n in ns:\n",
    "            for ngram in ngrams(text, n):\n",
    "                if ngram in testset_ngrams:\n",
    "                    dirty_hits[ngram] += 1\n",
    "    print(\"Concating now\")\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(data={\"ngram\": [k], \"dirty_count\": [v]})\n",
    "            for k, v in dirty_hits.items()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 56\n",
    "pool = Pool()\n",
    "results_df = pd.concat(\n",
    "    tqdm(\n",
    "        pool.imap_unordered(\n",
    "            partial(\n",
    "                check_contamination_books, testset_ngrams=testset_ngrams, ns=ns\n",
    "            ),\n",
    "            zip(np.array_split(book_files, n_cores), list(range(n_cores))),\n",
    "        ),\n",
    "        total=n_cores,\n",
    "        leave=False,\n",
    "        position=0,\n",
    "        desc=\"Global progress\",\n",
    "    ),\n",
    "    ignore_index=True,\n",
    ")\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = results_df.groupby([\"ngram\"], as_index=False).agg({\"dirty_count\": \"sum\"})\n",
    "agg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df.to_csv(\"contamination_bookscorpus.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = pd.read_csv(\"contamination_bookscorpus.tsv\", sep=\"\\t\")\n",
    "agg_results_df[\"ngram\"] = agg_results_df[\"ngram\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65174</th>\n",
       "      <td>(is, the, best, way, to, get, rid, of)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112621</th>\n",
       "      <td>(that, way, you, do, have, to, worry, about)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56706</th>\n",
       "      <td>(how, do, you, say, i, love, you, in)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31879</th>\n",
       "      <td>(could, hear, him, over, the, sound, of, the)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>(a, hole, in, the, wall, the, size, of)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48432</th>\n",
       "      <td>(funded, with, tax, money, this, education, sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48431</th>\n",
       "      <td>(funded, with, tax, money, this, does, not, ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48430</th>\n",
       "      <td>(funded, with, tax, money, this, does, goes, b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48429</th>\n",
       "      <td>(funded, with, tax, money, funding, with, tax,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145293</th>\n",
       "      <td>(zygote, with, a, woman, with, an, rr, allele,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ngram  dirty_count\n",
       "65174              (is, the, best, way, to, get, rid, of)            9\n",
       "112621       (that, way, you, do, have, to, worry, about)            8\n",
       "56706               (how, do, you, say, i, love, you, in)            6\n",
       "31879       (could, hear, him, over, the, sound, of, the)            5\n",
       "3171              (a, hole, in, the, wall, the, size, of)            5\n",
       "...                                                   ...          ...\n",
       "48432   (funded, with, tax, money, this, education, sh...            0\n",
       "48431   (funded, with, tax, money, this, does, not, ha...            0\n",
       "48430   (funded, with, tax, money, this, does, goes, b...            0\n",
       "48429   (funded, with, tax, money, funding, with, tax,...            0\n",
       "145293  (zygote, with, a, woman, with, an, rr, allele,...            0\n",
       "\n",
       "[145294 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_df.sort_values(\"dirty_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(agg_results_df[\"dirty_count\"] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(a, dream, of, hers, for, a, long, time)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(a, hole, in, the, wall, the, size, of)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(a, loaf, of, bread, with, a, jar, of)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(about, the, same, thing, over, and, over, again)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(along, the, seam, at, the, bottom, of, the)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>(what, will, you, do, if, you, do, not)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>(where, is, a, good, place, to, put, a)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>(where, will, you, go, when, you, die, heaven)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>(will, take, a, certain, amount, of, time, to)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>(your, garden, at, the, beginning, of, the, se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ngram  dirty_count\n",
       "0            (a, dream, of, hers, for, a, long, time)            1\n",
       "1             (a, hole, in, the, wall, the, size, of)            5\n",
       "2              (a, loaf, of, bread, with, a, jar, of)            1\n",
       "3   (about, the, same, thing, over, and, over, again)            4\n",
       "4        (along, the, seam, at, the, bottom, of, the)            1\n",
       "..                                                ...          ...\n",
       "67            (what, will, you, do, if, you, do, not)            1\n",
       "68            (where, is, a, good, place, to, put, a)            1\n",
       "69     (where, will, you, go, when, you, die, heaven)            2\n",
       "70     (will, take, a, certain, amount, of, time, to)            1\n",
       "71  (your, garden, at, the, beginning, of, the, se...            1\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dirty_hits = agg_results_df[agg_results_df[\"dirty_count\"] > 0].reset_index(drop=True)\n",
    "books_dirty_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14c2d237164400abda80630a5eac32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(books_dirty_hits.iterrows(), total=len(books_dirty_hits)):\n",
    "    for dirty_hit_df, lookup in tasks_df_and_lookup:\n",
    "        if row.ngram in lookup:\n",
    "            for ex_num in lookup[row.ngram]:\n",
    "                dirty_hit_df.at[ex_num, \"BookCorpus_hits\"] += row.dirty_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics after BookCorpus\n",
      "ARC: 10/1172 (0.8532423208191127%)\n",
      "CSQA: 55/1221 (4.504504504504505%)\n",
      "ARCT: 0/888 (0.0%)\n",
      "PIQA: 177/1838 (9.630032644178455%)\n"
     ]
    }
   ],
   "source": [
    "arc_ex_dirty_num = (\n",
    "    (arc_dirty_hits[\"BookCorpus_hits\"] > 0) | (arc_dirty_hits[\"ccnews_hits\"] > 0) | (arc_dirty_hits[\"openwebtext_hits\"] > 0) | (arc_dirty_hits[\"stories_hits\"] > 0) | (arc_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "csqa_ex_dirty_num = (\n",
    "    (csqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (csqa_dirty_hits[\"ccnews_hits\"] > 0) | (csqa_dirty_hits[\"openwebtext_hits\"] > 0) | (csqa_dirty_hits[\"stories_hits\"] > 0) | (csqa_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "arct_ex_dirty_num = (\n",
    "    (arct_dirty_hits[\"BookCorpus_hits\"] > 0) | (arct_dirty_hits[\"ccnews_hits\"] > 0) | (arct_dirty_hits[\"openwebtext_hits\"] > 0) | (arct_dirty_hits[\"stories_hits\"] > 0) | (arct_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "piqa_ex_dirty_num = (\n",
    "    (piqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (piqa_dirty_hits[\"ccnews_hits\"] > 0) | (piqa_dirty_hits[\"openwebtext_hits\"] > 0) | (piqa_dirty_hits[\"stories_hits\"] > 0) | (piqa_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "\n",
    "print(\"Statistics after BookCorpus\")\n",
    "print(f\"ARC: {arc_ex_dirty_num}/{len(arc_dirty_hits)} ({(arc_ex_dirty_num/len(arc_dirty_hits)) * 100}%)\")\n",
    "print(f\"CSQA: {csqa_ex_dirty_num}/{len(csqa_dirty_hits)} ({(csqa_ex_dirty_num/len(csqa_dirty_hits)) * 100}%)\")\n",
    "print(f\"ARCT: {arct_ex_dirty_num}/{len(arct_dirty_hits)} ({(arct_ex_dirty_num/len(arct_dirty_hits)) * 100}%)\")\n",
    "print(f\"PIQA: {piqa_ex_dirty_num}/{len(piqa_dirty_hits)} ({(piqa_ex_dirty_num/len(piqa_dirty_hits)) * 100}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia En"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('wikipedia', '20200501.en', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contamination_wikipedia(args, testset_ngrams=None, ns=None):\n",
    "    dirty_hits = {ngram: 0 for ngram in testset_ngrams}\n",
    "    ds = load_dataset('wikipedia', '20200501.en', split=\"train\")\n",
    "    idxs, n_worker = args\n",
    "    # cos jupyterlab is dumb\n",
    "    print(' ', end='', flush=True)\n",
    "    for idx, ds_idx in tqdm(enumerate(idxs), total=len(idxs), position=n_worker+1, leave=False, desc=f\"Worker #{n_worker}\"):\n",
    "        text = tokenize(ds[int(ds_idx)][\"text\"])\n",
    "        for n in ns:\n",
    "            for ngram in ngrams(text, n):\n",
    "                if ngram in testset_ngrams:\n",
    "                    dirty_hits[ngram] += 1\n",
    "    print(\"Concating now\")\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(data={\"ngram\": [k], \"dirty_count\": [v]})\n",
    "            for k, v in dirty_hits.items()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 else race condition\n",
    "n_cores = 32\n",
    "pool = Pool()\n",
    "results_df = pd.concat(\n",
    "    tqdm(\n",
    "        pool.imap_unordered(\n",
    "            partial(\n",
    "                check_contamination_wikipedia, testset_ngrams=testset_ngrams, ns=ns\n",
    "            ),\n",
    "            zip(np.array_split(range(len(ds)), n_cores), list(range(n_cores)))\n",
    "        ),\n",
    "        total=n_cores,\n",
    "        leave=False,\n",
    "        position=0,\n",
    "        desc=\"Global progress\"\n",
    "    ),\n",
    "    ignore_index=True,\n",
    ")\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = results_df.groupby([\"ngram\"], as_index=False).agg({\"dirty_count\": \"sum\"})\n",
    "agg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df.to_csv(\"contamination_wikipedia.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = pd.read_csv(\"contamination_wikipedia.tsv\", sep=\"\\t\")\n",
    "agg_results_df[\"ngram\"] = agg_results_df[\"ngram\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43104</th>\n",
       "      <td>(faint, constellation, in, the, southern, sky,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63457</th>\n",
       "      <td>(is, a, small, faint, constellation, in, the, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77237</th>\n",
       "      <td>(mussels, and, other, shellfish, that, have, n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30924</th>\n",
       "      <td>(constellation, in, the, southern, sky, first,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47228</th>\n",
       "      <td>(french, astronomer, de, lacaille, its, name, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48433</th>\n",
       "      <td>(funded, with, tax, money, this, education, sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48432</th>\n",
       "      <td>(funded, with, tax, money, this, education, sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48431</th>\n",
       "      <td>(funded, with, tax, money, this, does, not, ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48430</th>\n",
       "      <td>(funded, with, tax, money, this, does, goes, b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145293</th>\n",
       "      <td>(zygote, with, a, woman, with, an, rr, allele,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ngram  dirty_count\n",
       "43104   (faint, constellation, in, the, southern, sky,...            2\n",
       "63457   (is, a, small, faint, constellation, in, the, ...            2\n",
       "77237   (mussels, and, other, shellfish, that, have, n...            2\n",
       "30924   (constellation, in, the, southern, sky, first,...            2\n",
       "47228   (french, astronomer, de, lacaille, its, name, ...            2\n",
       "...                                                   ...          ...\n",
       "48433   (funded, with, tax, money, this, education, sh...            0\n",
       "48432   (funded, with, tax, money, this, education, sh...            0\n",
       "48431   (funded, with, tax, money, this, does, not, ha...            0\n",
       "48430   (funded, with, tax, money, this, does, goes, b...            0\n",
       "145293  (zygote, with, a, woman, with, an, rr, allele,...            0\n",
       "\n",
       "[145294 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_df.sort_values(\"dirty_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(agg_results_df[\"dirty_count\"] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1756, by, the, french, astronomer, de, lacail...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(a, hole, in, the, top, of, the, can)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(a, magnet, when, the, magnet, is, moved, away...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(a, small, faint, constellation, in, the, sout...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(astronomer, de, lacaille, its, name, is, lati...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(at, something, 20, feet, away, for, 20, seconds)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(but, did, want, to, go, to, the, hospital)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(by, the, french, astronomer, de, lacaille, it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(can, be, very, dangerous, and, can, lead, to)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(circinus, is, a, small, faint, constellation,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(coast, of, south, america, and, the, west, co...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(constellation, in, the, southern, sky, first,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(de, lacaille, its, name, is, latin, for, comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(defined, in, 1756, by, the, french, astronome...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(east, coast, of, south, america, and, the, we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(faint, constellation, in, the, southern, sky,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(first, defined, in, 1756, by, the, french, as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(first, law, of, motion, states, that, an, obj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(french, astronomer, de, lacaille, its, name, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(how, to, find, the, surface, area, of, a)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(in, 1756, by, the, french, astronomer, de, la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(in, both, the, atlantic, ocean, and, the, gul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(in, one, hand, and, the, knife, in, the)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(in, order, to, see, what, is, going, on)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(in, the, southern, sky, first, defined, in, 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(is, a, faint, constellation, in, the, souther...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(is, a, hole, in, the, bottom, of, the)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(is, a, small, faint, constellation, in, the, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(is, equal, to, the, area, of, the, parallelog...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(is, the, length, of, one, of, the, sides)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(is, the, same, color, as, most, of, the)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(law, of, motion, states, that, an, object, at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(look, at, something, 20, feet, away, for, 20)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(mussels, and, other, shellfish, that, have, n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(newton, first, law, of, motion, states, that,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(one, hand, and, the, knife, in, the, other)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(should, be, planted, in, soil, in, an, area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(sky, first, defined, in, 1756, by, the, french)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(small, faint, constellation, in, the, souther...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(southern, sky, first, defined, in, 1756, by, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(that, he, could, get, away, with, it, he)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(the, east, coast, of, south, america, and, th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(the, french, astronomer, de, lacaille, its, n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(the, southern, sky, first, defined, in, 1756,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(there, is, a, hole, in, the, bottom, of)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(was, going, to, grow, up, to, be, a)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ngram  dirty_count\n",
       "0   (1756, by, the, french, astronomer, de, lacail...            1\n",
       "1               (a, hole, in, the, top, of, the, can)            1\n",
       "2   (a, magnet, when, the, magnet, is, moved, away...            1\n",
       "3   (a, small, faint, constellation, in, the, sout...            2\n",
       "4   (astronomer, de, lacaille, its, name, is, lati...            2\n",
       "5   (at, something, 20, feet, away, for, 20, seconds)            1\n",
       "6         (but, did, want, to, go, to, the, hospital)            1\n",
       "7   (by, the, french, astronomer, de, lacaille, it...            1\n",
       "8      (can, be, very, dangerous, and, can, lead, to)            1\n",
       "9   (circinus, is, a, small, faint, constellation,...            1\n",
       "10  (coast, of, south, america, and, the, west, co...            2\n",
       "11  (constellation, in, the, southern, sky, first,...            2\n",
       "12  (de, lacaille, its, name, is, latin, for, comp...            1\n",
       "13  (defined, in, 1756, by, the, french, astronome...            1\n",
       "14  (east, coast, of, south, america, and, the, we...            1\n",
       "15  (faint, constellation, in, the, southern, sky,...            2\n",
       "16  (first, defined, in, 1756, by, the, french, as...            1\n",
       "17  (first, law, of, motion, states, that, an, obj...            1\n",
       "18  (french, astronomer, de, lacaille, its, name, ...            2\n",
       "19         (how, to, find, the, surface, area, of, a)            1\n",
       "20  (in, 1756, by, the, french, astronomer, de, la...            1\n",
       "21  (in, both, the, atlantic, ocean, and, the, gul...            1\n",
       "22          (in, one, hand, and, the, knife, in, the)            1\n",
       "23          (in, order, to, see, what, is, going, on)            1\n",
       "24  (in, the, southern, sky, first, defined, in, 1...            1\n",
       "25  (is, a, faint, constellation, in, the, souther...            2\n",
       "26            (is, a, hole, in, the, bottom, of, the)            1\n",
       "27  (is, a, small, faint, constellation, in, the, ...            2\n",
       "28  (is, equal, to, the, area, of, the, parallelog...            1\n",
       "29         (is, the, length, of, one, of, the, sides)            1\n",
       "30          (is, the, same, color, as, most, of, the)            1\n",
       "31  (law, of, motion, states, that, an, object, at...            1\n",
       "32     (look, at, something, 20, feet, away, for, 20)            1\n",
       "33  (mussels, and, other, shellfish, that, have, n...            2\n",
       "34  (newton, first, law, of, motion, states, that,...            1\n",
       "35       (one, hand, and, the, knife, in, the, other)            1\n",
       "36      (should, be, planted, in, soil, in, an, area)            1\n",
       "37   (sky, first, defined, in, 1756, by, the, french)            1\n",
       "38  (small, faint, constellation, in, the, souther...            1\n",
       "39  (southern, sky, first, defined, in, 1756, by, ...            1\n",
       "40         (that, he, could, get, away, with, it, he)            1\n",
       "41  (the, east, coast, of, south, america, and, th...            1\n",
       "42  (the, french, astronomer, de, lacaille, its, n...            1\n",
       "43  (the, southern, sky, first, defined, in, 1756,...            1\n",
       "44          (there, is, a, hole, in, the, bottom, of)            1\n",
       "45              (was, going, to, grow, up, to, be, a)            1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_dirty_hits = agg_results_df[agg_results_df[\"dirty_count\"] > 0].reset_index(drop=True)\n",
    "wikipedia_dirty_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0496bce41594454aa73de330826593c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(wikipedia_dirty_hits.iterrows(), total=len(wikipedia_dirty_hits)):\n",
    "    for dirty_hit_df, lookup in tasks_df_and_lookup:\n",
    "        if row.ngram in lookup:\n",
    "            for ex_num in lookup[row.ngram]:\n",
    "                dirty_hit_df.at[ex_num, \"wikipedia_hits\"] += row.dirty_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics after Wikipedia\n",
      "ARC: 11/1172 (0.938566552901024%)\n",
      "CSQA: 56/1221 (4.586404586404586%)\n",
      "ARCT: 0/888 (0.0%)\n",
      "PIQA: 180/1838 (9.793253536452665%)\n"
     ]
    }
   ],
   "source": [
    "arc_ex_dirty_num = (\n",
    "    (arc_dirty_hits[\"BookCorpus_hits\"] > 0) | (arc_dirty_hits[\"ccnews_hits\"] > 0) | (arc_dirty_hits[\"openwebtext_hits\"] > 0) | (arc_dirty_hits[\"stories_hits\"] > 0) | (arc_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "csqa_ex_dirty_num = (\n",
    "    (csqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (csqa_dirty_hits[\"ccnews_hits\"] > 0) | (csqa_dirty_hits[\"openwebtext_hits\"] > 0) | (csqa_dirty_hits[\"stories_hits\"] > 0) | (csqa_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "arct_ex_dirty_num = (\n",
    "    (arct_dirty_hits[\"BookCorpus_hits\"] > 0) | (arct_dirty_hits[\"ccnews_hits\"] > 0) | (arct_dirty_hits[\"openwebtext_hits\"] > 0) | (arct_dirty_hits[\"stories_hits\"] > 0) | (arct_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "piqa_ex_dirty_num = (\n",
    "    (piqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (piqa_dirty_hits[\"ccnews_hits\"] > 0) | (piqa_dirty_hits[\"openwebtext_hits\"] > 0) | (piqa_dirty_hits[\"stories_hits\"] > 0) | (piqa_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "\n",
    "print(\"Statistics after Wikipedia\")\n",
    "print(f\"ARC: {arc_ex_dirty_num}/{len(arc_dirty_hits)} ({(arc_ex_dirty_num/len(arc_dirty_hits)) * 100}%)\")\n",
    "print(f\"CSQA: {csqa_ex_dirty_num}/{len(csqa_dirty_hits)} ({(csqa_ex_dirty_num/len(csqa_dirty_hits)) * 100}%)\")\n",
    "print(f\"ARCT: {arct_ex_dirty_num}/{len(arct_dirty_hits)} ({(arct_ex_dirty_num/len(arct_dirty_hits)) * 100}%)\")\n",
    "print(f\"PIQA: {piqa_ex_dirty_num}/{len(piqa_dirty_hits)} ({(piqa_ex_dirty_num/len(piqa_dirty_hits)) * 100}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CC-News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use crawl_ccnews.py\n",
    "PATH_TO_CCNEWS = \"\"\n",
    "\n",
    "cc_files = glob(os.path.join(PATH_TO_CCNEWS,\"*\", \"*.json\"), recursive=True)\n",
    "len(cc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify(a, batch_size=2):\n",
    "    for i in range(a.shape[0] // batch_size):\n",
    "        yield a[batch_size * i: batch_size * (i + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contamination_ccnews(args, testset_ngrams=None, ns=None):\n",
    "    dirty_hits = {ngram: 0 for ngram in testset_ngrams}\n",
    "    files, n_worker = args\n",
    "    batch_size = 1500\n",
    "    # cos jupyterlab is dumb\n",
    "    log_file = None\n",
    "    print(' ', end='', flush=True)\n",
    "    for _files in tqdm(chunkify(files, batch_size), total=len(files) // batch_size, position=n_worker+1, leave=False, desc=f\"Worker #{n_worker}\"):\n",
    "        js = []\n",
    "        for file_name in _files:\n",
    "            try:\n",
    "                with open(file_name, \"rt\") as f:\n",
    "                    js.append(json.load(f))\n",
    "            except Exception as e:\n",
    "                if log_file is None:\n",
    "                    log_file = open(f\"error_worker#{n_worker}.log\", \"wt\")\n",
    "                print(f\"{file_name}\\t{repr(e)}\", file=log_file, end=\"\\n\")\n",
    "\n",
    "        for j in js:\n",
    "            if j[\"maintext\"] is not None:\n",
    "                text = tokenize(j[\"maintext\"])\n",
    "                for n in ns:\n",
    "                    for ngram in ngrams(text, n):\n",
    "                        if ngram in testset_ngrams:\n",
    "                            dirty_hits[ngram] += 1\n",
    "\n",
    "    if log_file is not None:\n",
    "        log_file.close()\n",
    "\n",
    "    print(\"Concating now\")\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(data={\"ngram\": [k], \"dirty_count\": [v]})\n",
    "            for k, v in dirty_hits.items()\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 88\n",
    "pool = Pool()\n",
    "results_df = pd.concat(\n",
    "    tqdm(\n",
    "        pool.imap_unordered(\n",
    "            partial(\n",
    "                check_contamination_ccnews, testset_ngrams=testset_ngrams, ns=ns\n",
    "            ),\n",
    "            zip(np.array_split(cc_files, n_cores), list(range(n_cores))),\n",
    "        ),\n",
    "        total=n_cores,\n",
    "        leave=False,\n",
    "        position=0,\n",
    "        desc=\"Global progress\",\n",
    "    ),\n",
    "    ignore_index=True,\n",
    ")\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = results_df.groupby([\"ngram\"], as_index=False).agg({\"dirty_count\": \"sum\"})\n",
    "agg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df.to_csv(\"contamination_ccnews.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = pd.read_csv(\"contamination_ccnews.tsv\", sep=\"\\t\")\n",
    "agg_results_df[\"ngram\"] = agg_results_df[\"ngram\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59383</th>\n",
       "      <td>(in, a, large, skillet, over, medium, heat, add)</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85437</th>\n",
       "      <td>(oil, in, a, large, skillet, over, medium, heat)</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123931</th>\n",
       "      <td>(to, a, boil, then, reduce, the, heat, to)</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12396</th>\n",
       "      <td>(and, season, to, taste, with, salt, and, pepper)</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11731</th>\n",
       "      <td>(and, lemon, juice, season, with, salt, and, p...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48520</th>\n",
       "      <td>(g, of, water, in, a, cup, another, group, of,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48519</th>\n",
       "      <td>(g, of, table, salt, in, a, glass, of, water, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48518</th>\n",
       "      <td>(g, of, strawberries, cup, 67, g, of, molasses)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48517</th>\n",
       "      <td>(g, of, strawberries, cup, 67, g, of, granulated)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145293</th>\n",
       "      <td>(zygote, with, a, woman, with, an, rr, allele,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ngram  dirty_count\n",
       "59383    (in, a, large, skillet, over, medium, heat, add)          264\n",
       "85437    (oil, in, a, large, skillet, over, medium, heat)          181\n",
       "123931         (to, a, boil, then, reduce, the, heat, to)          120\n",
       "12396   (and, season, to, taste, with, salt, and, pepper)          114\n",
       "11731   (and, lemon, juice, season, with, salt, and, p...          112\n",
       "...                                                   ...          ...\n",
       "48520   (g, of, water, in, a, cup, another, group, of,...            0\n",
       "48519   (g, of, table, salt, in, a, glass, of, water, ...            0\n",
       "48518     (g, of, strawberries, cup, 67, g, of, molasses)            0\n",
       "48517   (g, of, strawberries, cup, 67, g, of, granulated)            0\n",
       "145293  (zygote, with, a, woman, with, an, rr, allele,...            0\n",
       "\n",
       "[145294 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_df.sort_values(\"dirty_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(agg_results_df[\"dirty_count\"] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(15, to, 20, minutes, or, until, a, toothpick)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2, tablespoons, butter, season, with, salt, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2, tsp, onion, powder, 1, tsp, sea, salt)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(20, feet, away, for, 20, seconds, every, 20)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(20, minutes, or, until, a, toothpick, inserte...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>(your, lash, line, each, night, with, a, and)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>(your, name, in, the, search, bar, on, the)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>(your, profile, picture, at, the, bottom, righ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>(your, username, at, the, top, of, the, page)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>(your, word, do, what, you, say, you, will)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ngram  dirty_count\n",
       "0       (15, to, 20, minutes, or, until, a, toothpick)            5\n",
       "1    (2, tablespoons, butter, season, with, salt, a...            1\n",
       "2           (2, tsp, onion, powder, 1, tsp, sea, salt)            1\n",
       "3        (20, feet, away, for, 20, seconds, every, 20)           15\n",
       "4    (20, minutes, or, until, a, toothpick, inserte...           12\n",
       "..                                                 ...          ...\n",
       "590      (your, lash, line, each, night, with, a, and)            1\n",
       "591        (your, name, in, the, search, bar, on, the)            1\n",
       "592  (your, profile, picture, at, the, bottom, righ...            1\n",
       "593      (your, username, at, the, top, of, the, page)            2\n",
       "594        (your, word, do, what, you, say, you, will)            1\n",
       "\n",
       "[595 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccnews_dirty_hits = agg_results_df[agg_results_df[\"dirty_count\"] > 0].reset_index(drop=True)\n",
    "ccnews_dirty_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5802d70eeded4665aa0be6202bd3c0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=595.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(ccnews_dirty_hits.iterrows(), total=len(ccnews_dirty_hits)):\n",
    "    for dirty_hit_df, lookup in tasks_df_and_lookup:\n",
    "        if row.ngram in lookup:\n",
    "            for ex_num in lookup[row.ngram]:\n",
    "                dirty_hit_df.at[ex_num, \"ccnews_hits\"] += row.dirty_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics after CCNews\n",
      "ARC: 14/1172 (1.1945392491467577%)\n",
      "CSQA: 62/1221 (5.077805077805078%)\n",
      "ARCT: 0/888 (0.0%)\n",
      "PIQA: 243/1838 (13.2208922742111%)\n"
     ]
    }
   ],
   "source": [
    "arc_ex_dirty_num = (\n",
    "    (arc_dirty_hits[\"BookCorpus_hits\"] > 0) | (arc_dirty_hits[\"ccnews_hits\"] > 0) | (arc_dirty_hits[\"openwebtext_hits\"] > 0) | (arc_dirty_hits[\"stories_hits\"] > 0) | (arc_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "csqa_ex_dirty_num = (\n",
    "    (csqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (csqa_dirty_hits[\"ccnews_hits\"] > 0) | (csqa_dirty_hits[\"openwebtext_hits\"] > 0) | (csqa_dirty_hits[\"stories_hits\"] > 0) | (csqa_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "arct_ex_dirty_num = (\n",
    "    (arct_dirty_hits[\"BookCorpus_hits\"] > 0) | (arct_dirty_hits[\"ccnews_hits\"] > 0) | (arct_dirty_hits[\"openwebtext_hits\"] > 0) | (arct_dirty_hits[\"stories_hits\"] > 0) | (arct_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "piqa_ex_dirty_num = (\n",
    "    (piqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (piqa_dirty_hits[\"ccnews_hits\"] > 0) | (piqa_dirty_hits[\"openwebtext_hits\"] > 0) | (piqa_dirty_hits[\"stories_hits\"] > 0) | (piqa_dirty_hits[\"wikipedia_hits\"] > 0)\n",
    ").sum()\n",
    "\n",
    "print(\"Statistics after CCNews\")\n",
    "print(f\"ARC: {arc_ex_dirty_num}/{len(arc_dirty_hits)} ({(arc_ex_dirty_num/len(arc_dirty_hits)) * 100}%)\")\n",
    "print(f\"CSQA: {csqa_ex_dirty_num}/{len(csqa_dirty_hits)} ({(csqa_ex_dirty_num/len(csqa_dirty_hits)) * 100}%)\")\n",
    "print(f\"ARCT: {arct_ex_dirty_num}/{len(arct_dirty_hits)} ({(arct_ex_dirty_num/len(arct_dirty_hits)) * 100}%)\")\n",
    "print(f\"PIQA: {piqa_ex_dirty_num}/{len(piqa_dirty_hits)} ({(piqa_ex_dirty_num/len(piqa_dirty_hits)) * 100}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATOMIC2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_ATOMIC = \"\"\n",
    "df = pd.read_csv(os.path.join(PATH_TO_ATOMIC, \"train.tsv\"), sep=\"\\t\", header=None, names=[\"head\", \"rel\", \"tail\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tail\"] = df[\"tail\"].apply(lambda x: \"nan\" if isinstance(x, float) else x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contamination_atomic(args, testset_ngrams=None, ns=None):\n",
    "    dirty_hits = {ngram: 0 for ngram in testset_ngrams}\n",
    "    df, n_worker = args\n",
    "    # cos jupyterlab is dumb\n",
    "    print(' ', end='', flush=True)\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), position=n_worker+1, leave=False, desc=f\"Worker #{n_worker}\"):\n",
    "        text = tokenize(\" \".join([row[\"tail\"], row[\"rel\"], row[\"tail\"]]))\n",
    "        for n in ns:\n",
    "            for ngram in ngrams(text, n):\n",
    "                if ngram in testset_ngrams:\n",
    "                    dirty_hits[ngram] += 1\n",
    "    print(\"Concating now\")\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(data={\"ngram\": [k], \"dirty_count\": [v]})\n",
    "            for k, v in dirty_hits.items()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 16\n",
    "pool = Pool()\n",
    "results_df = pd.concat(\n",
    "    tqdm(\n",
    "        pool.imap_unordered(\n",
    "            partial(\n",
    "                check_contamination_atomic, testset_ngrams=testset_ngrams, ns=ns\n",
    "            ),\n",
    "            zip(np.array_split(df, n_cores), list(range(n_cores)))\n",
    "        ),\n",
    "        total=n_cores,\n",
    "        leave=False,\n",
    "        position=0,\n",
    "        desc=\"Global progress\"\n",
    "    ),\n",
    "    ignore_index=True,\n",
    ")\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = results_df.groupby([\"ngram\"], as_index=False).agg({\"dirty_count\": \"sum\"})\n",
    "agg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df.to_csv(\"contamination_atomic.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_df = pd.read_csv(\"contamination_atomic.tsv\", sep=\"\\t\")\n",
    "agg_results_df[\"ngram\"] = agg_results_df[\"ngram\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 16, ounce, can, chocolate, flavored, syrup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96865</th>\n",
       "      <td>(reading, them, other, people, often, think, s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96859</th>\n",
       "      <td>(reading, them, comment, sections, have, faile...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96860</th>\n",
       "      <td>(reading, them, comment, sections, have, not, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96861</th>\n",
       "      <td>(reading, them, comment, sections, have, not, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48425</th>\n",
       "      <td>(funded, with, tax, money, college, should, no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48424</th>\n",
       "      <td>(funded, with, tax, money, college, should, no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48423</th>\n",
       "      <td>(funded, with, tax, money, college, should, no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48422</th>\n",
       "      <td>(funded, with, tax, money, college, should, be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145293</th>\n",
       "      <td>(zygote, with, a, woman, with, an, rr, allele,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ngram  dirty_count\n",
       "0       (1, 16, ounce, can, chocolate, flavored, syrup...            0\n",
       "96865   (reading, them, other, people, often, think, s...            0\n",
       "96859   (reading, them, comment, sections, have, faile...            0\n",
       "96860   (reading, them, comment, sections, have, not, ...            0\n",
       "96861   (reading, them, comment, sections, have, not, ...            0\n",
       "...                                                   ...          ...\n",
       "48425   (funded, with, tax, money, college, should, no...            0\n",
       "48424   (funded, with, tax, money, college, should, no...            0\n",
       "48423   (funded, with, tax, money, college, should, no...            0\n",
       "48422   (funded, with, tax, money, college, should, be...            0\n",
       "145293  (zygote, with, a, woman, with, an, rr, allele,...            0\n",
       "\n",
       "[145294 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_df.sort_values(\"dirty_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(agg_results_df[\"dirty_count\"] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>dirty_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ngram, dirty_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_dirty_hits = agg_results_df[agg_results_df[\"dirty_count\"] > 0].reset_index(drop=True)\n",
    "atomic_dirty_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cdd8e070074ff59a3eaf0dd1235458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(atomic_dirty_hits.iterrows(), total=len(atomic_dirty_hits)):\n",
    "    for dirty_hit_df, lookup in tasks_df_and_lookup:\n",
    "        if row.ngram in lookup:\n",
    "            for ex_num in lookup[row.ngram]:\n",
    "                dirty_hit_df.at[ex_num, \"atomic_hits\"] += row.dirty_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics after ATOMIC\n",
      "ARC: 14/1172 (1.1945392491467577%)\n",
      "CSQA: 62/1221 (5.077805077805078%)\n",
      "ARCT: 0/888 (0.0%)\n",
      "PIQA: 243/1838 (13.2208922742111%)\n"
     ]
    }
   ],
   "source": [
    "arc_ex_dirty_num = (\n",
    "    (arc_dirty_hits[\"BookCorpus_hits\"] > 0) | (arc_dirty_hits[\"ccnews_hits\"] > 0) | (arc_dirty_hits[\"openwebtext_hits\"] > 0) | (arc_dirty_hits[\"stories_hits\"] > 0) | (arc_dirty_hits[\"wikipedia_hits\"] > 0) | (arc_dirty_hits[\"atomic_hits\"] > 0)\n",
    ").sum()\n",
    "csqa_ex_dirty_num = (\n",
    "    (csqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (csqa_dirty_hits[\"ccnews_hits\"] > 0) | (csqa_dirty_hits[\"openwebtext_hits\"] > 0) | (csqa_dirty_hits[\"stories_hits\"] > 0) | (csqa_dirty_hits[\"wikipedia_hits\"] > 0) | (csqa_dirty_hits[\"atomic_hits\"] > 0)\n",
    ").sum()\n",
    "arct_ex_dirty_num = (\n",
    "    (arct_dirty_hits[\"BookCorpus_hits\"] > 0) | (arct_dirty_hits[\"ccnews_hits\"] > 0) | (arct_dirty_hits[\"openwebtext_hits\"] > 0) | (arct_dirty_hits[\"stories_hits\"] > 0) | (arct_dirty_hits[\"wikipedia_hits\"] > 0) | (arct_dirty_hits[\"atomic_hits\"] > 0)\n",
    ").sum()\n",
    "piqa_ex_dirty_num = (\n",
    "    (piqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (piqa_dirty_hits[\"ccnews_hits\"] > 0) | (piqa_dirty_hits[\"openwebtext_hits\"] > 0) | (piqa_dirty_hits[\"stories_hits\"] > 0) | (piqa_dirty_hits[\"wikipedia_hits\"] > 0) | (piqa_dirty_hits[\"atomic_hits\"] > 0)\n",
    ").sum()\n",
    "\n",
    "print(\"Statistics after ATOMIC\")\n",
    "print(f\"ARC: {arc_ex_dirty_num}/{len(arc_dirty_hits)} ({(arc_ex_dirty_num/len(arc_dirty_hits)) * 100}%)\")\n",
    "print(f\"CSQA: {csqa_ex_dirty_num}/{len(csqa_dirty_hits)} ({(csqa_ex_dirty_num/len(csqa_dirty_hits)) * 100}%)\")\n",
    "print(f\"ARCT: {arct_ex_dirty_num}/{len(arct_dirty_hits)} ({(arct_ex_dirty_num/len(arct_dirty_hits)) * 100}%)\")\n",
    "print(f\"PIQA: {piqa_ex_dirty_num}/{len(piqa_dirty_hits)} ({(piqa_ex_dirty_num/len(piqa_dirty_hits)) * 100}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa PIQA Influence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(\"..\", \"RoBERTa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import RobertaForMultipleChoicePIQA\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    learning_rate=1e-3,\n",
    "    gradient_accumulation_steps=0,\n",
    "    seed=42,\n",
    "    model_name=\"roberta-large\",\n",
    "    batch_size=32,\n",
    "    max_seq_len=115,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.06,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForMultipleChoice: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_ROBERTA_PIQA_MODEL_CHECKPOINT = \"\"\n",
    "\n",
    "roberta = RobertaForMultipleChoicePIQA.load_from_checkpoint(\n",
    "    PATH_TO_ROBERTA_PIQA_MODEL_CHECKPOINT,\n",
    "    hparams=hparams,\n",
    "    data_path=os.path.join(\"..\", \"data\", \"PIQA\"),\n",
    "    epochs=10,\n",
    "    lr_schedule=None,\n",
    "    num_classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = roberta.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "piqa_dirty = (piqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (piqa_dirty_hits[\"ccnews_hits\"] > 0) | (piqa_dirty_hits[\"openwebtext_hits\"] > 0) | (piqa_dirty_hits[\"stories_hits\"] > 0) | (piqa_dirty_hits[\"wikipedia_hits\"] > 0) | (piqa_dirty_hits[\"atomic_hits\"] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  18,   22,   29,   47,   68,   82,   85,   87,   96,  107,  135,\n",
       "        139,  142,  147,  152,  157,  159,  164,  167,  199,  200,  216,\n",
       "        220,  223,  227,  233,  237,  239,  242,  244,  247,  254,  264,\n",
       "        267,  273,  274,  275,  276,  278,  282,  283,  292,  306,  313,\n",
       "        314,  318,  337,  346,  354,  361,  362,  363,  373,  374,  393,\n",
       "        414,  425,  430,  431,  437,  443,  470,  474,  480,  485,  513,\n",
       "        514,  518,  522,  544,  546,  553,  562,  569,  581,  587,  590,\n",
       "        596,  639,  641,  648,  650,  654,  679,  692,  702,  703,  705,\n",
       "        710,  712,  717,  735,  738,  743,  745,  746,  747,  768,  772,\n",
       "        782,  786,  800,  828,  831,  835,  849,  852,  858,  860,  861,\n",
       "        870,  871,  880,  886,  891,  920,  922,  928,  936,  939,  944,\n",
       "        946,  956,  962,  969,  976,  985,  987,  990,  997, 1010, 1013,\n",
       "       1027, 1037, 1046, 1054, 1057, 1066, 1078, 1085, 1086, 1097, 1099,\n",
       "       1105, 1112, 1119, 1127, 1138, 1157, 1161, 1169, 1171, 1176, 1177,\n",
       "       1190, 1193, 1202, 1205, 1214, 1217, 1219, 1226, 1230, 1252, 1260,\n",
       "       1270, 1276, 1282, 1286, 1287, 1294, 1295, 1304, 1330, 1339, 1341,\n",
       "       1345, 1353, 1358, 1360, 1361, 1376, 1378, 1384, 1389, 1405, 1432,\n",
       "       1433, 1451, 1453, 1460, 1461, 1465, 1468, 1475, 1479, 1480, 1489,\n",
       "       1490, 1495, 1501, 1511, 1530, 1543, 1554, 1565, 1569, 1573, 1584,\n",
       "       1592, 1595, 1597, 1614, 1617, 1619, 1622, 1632, 1634, 1638, 1644,\n",
       "       1657, 1661, 1662, 1665, 1667, 1672, 1674, 1683, 1705, 1708, 1715,\n",
       "       1717, 1725, 1736, 1742, 1750, 1777, 1791, 1801, 1812, 1817, 1825,\n",
       "       1833])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piqa_dirty_idxs = np.nonzero(piqa_dirty.values)[0]\n",
    "piqa_dirty_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "piqa_clean_idxs = np.nonzero(~piqa_dirty.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14501/14501 [00:09<00:00, 1565.07it/s]\n",
      "100%|██████████| 1612/1612 [00:00<00:00, 1645.64it/s]\n",
      "100%|██████████| 1838/1838 [00:01<00:00, 1647.00it/s]\n"
     ]
    }
   ],
   "source": [
    "roberta.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "b_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    while b_idx * 32 < len(roberta.test_data):\n",
    "        input_ids, attention_mask, y = roberta.test_data[b_idx * 32: b_idx * 32 + 32]\n",
    "        input_ids, attention_mask = input_ids.cuda(), attention_mask.cuda()\n",
    "        ys = roberta(input_ids, attention_mask)[0].cpu()\n",
    "        input_ids, attention_mask = input_ids.cpu(), attention_mask.cpu()\n",
    "        y_pred.extend(ys.cpu().tolist())\n",
    "        y_true.extend(y.tolist())\n",
    "        b_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353909465020576"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[piqa_dirty_idxs], y_pred[piqa_dirty_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7893416927899687"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[piqa_clean_idxs], y_pred[piqa_clean_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = roberta.cpu()\n",
    "del roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARC RoBERTa Influence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import RobertaForRankingARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    learning_rate=1e-3,\n",
    "    gradient_accumulation_steps=0,\n",
    "    seed=42,\n",
    "    model_name=\"roberta-large\",\n",
    "    batch_size=32,\n",
    "    max_seq_len=90,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.06,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForVariableMultipleChoice: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForVariableMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForVariableMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForVariableMultipleChoice were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_ROBERTA_ARC_MODEL_CHECKPOINT = \"\"\n",
    "\n",
    "roberta = RobertaForRankingARC.load_from_checkpoint(\n",
    "    PATH_TO_ROBERTA_ARC_MODEL_CHECKPOINT,\n",
    "    hparams=hparams,\n",
    "    data_path=None,\n",
    "    epochs=10,\n",
    "    lr_schedule=None,\n",
    "    num_classes=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = roberta.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_dirty = (arc_dirty_hits[\"BookCorpus_hits\"] > 0) | (arc_dirty_hits[\"ccnews_hits\"] > 0) | (arc_dirty_hits[\"openwebtext_hits\"] > 0) | (arc_dirty_hits[\"stories_hits\"] > 0) | (arc_dirty_hits[\"wikipedia_hits\"] > 0) | (arc_dirty_hits[\"atomic_hits\"] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_dirty_idxs = np.nonzero(arc_dirty.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_clean_idxs = np.nonzero(~arc_dirty.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1119/1119 [00:01<00:00, 707.71it/s]\n",
      "100%|██████████| 299/299 [00:00<00:00, 719.67it/s]\n",
      "100%|██████████| 1172/1172 [00:01<00:00, 759.23it/s]\n"
     ]
    }
   ],
   "source": [
    "roberta.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "b_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    while b_idx * 32 < len(roberta.test_data):\n",
    "        input_ids, attention_mask, y = roberta.test_data[b_idx * 32: b_idx * 32 + 32]\n",
    "        input_ids, attention_mask = input_ids.cuda(), attention_mask.cuda()\n",
    "        ys = roberta(input_ids, attention_mask)[0].cpu()\n",
    "        input_ids, attention_mask = input_ids.cpu(), attention_mask.cpu()\n",
    "        y_pred.extend(ys.cpu().tolist())\n",
    "        y_true.extend(y.tolist())\n",
    "        b_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[arc_dirty_idxs], y_pred[arc_dirty_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4317789291882556"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[arc_clean_idxs], y_pred[arc_clean_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = roberta.cpu()\n",
    "del roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSQA RoBERTa Influence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import RobertaForCSQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    learning_rate=1e-3,\n",
    "    gradient_accumulation_steps=0,\n",
    "    seed=42,\n",
    "    model_name=\"roberta-large\",\n",
    "    batch_size=32,\n",
    "    max_seq_len=90,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.06,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForMultipleChoice: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_CSQA_MODEL_CHECKPOINT = \"\"\n",
    "\n",
    "roberta = RobertaForCSQA.load_from_checkpoint(\n",
    "    PATH_TO_CSQA_MODEL_CHECKPOINT,\n",
    "    hparams=hparams,\n",
    "    data_path=None,\n",
    "    epochs=10,\n",
    "    lr_schedule=None,\n",
    "    num_classes=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = roberta.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "csqa_dirty = (csqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (csqa_dirty_hits[\"ccnews_hits\"] > 0) | (csqa_dirty_hits[\"openwebtext_hits\"] > 0) | (csqa_dirty_hits[\"stories_hits\"] > 0) | (csqa_dirty_hits[\"wikipedia_hits\"] > 0) | (csqa_dirty_hits[\"atomic_hits\"] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "csqa_dirty_idxs = np.nonzero(csqa_dirty.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "csqa_clean_idxs = np.nonzero(~csqa_dirty.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8766/8766 [00:11<00:00, 794.53it/s]\n",
      "100%|██████████| 975/975 [00:01<00:00, 811.79it/s]\n",
      "100%|██████████| 1221/1221 [00:01<00:00, 782.96it/s]\n"
     ]
    }
   ],
   "source": [
    "roberta.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "b_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    while b_idx * 32 < len(roberta.test_data):\n",
    "        input_ids, attention_mask, y = roberta.test_data[b_idx * 32: b_idx * 32 + 32]\n",
    "        input_ids, attention_mask = input_ids.cuda(), attention_mask.cuda()\n",
    "        ys = roberta(input_ids, attention_mask)[0].cpu()\n",
    "        input_ids, attention_mask = input_ids.cpu(), attention_mask.cpu()\n",
    "        y_pred.extend(ys.cpu().tolist())\n",
    "        y_true.extend(y.tolist())\n",
    "        b_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7258064516129032"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[csqa_dirty_idxs], y_pred[csqa_dirty_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7385677308024159"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[csqa_clean_idxs], y_pred[csqa_clean_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = roberta.cpu()\n",
    "del roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMET(BART) PIQA Influence Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel here cos of import issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(\"..\", \"BART_AND_COMET\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BARTForPIQA\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_COMET_PRETRAIN_CHECKPOINT = \"\"\n",
    "\n",
    "hparams = Namespace(\n",
    "    learning_rate=1e-3,\n",
    "    gradient_accumulation_steps=0,\n",
    "    seed=42,\n",
    "    model_name=\"facebook/bart-large\",\n",
    "    pretrained_weights=PATH_COMET_PRETRAIN_CHECKPOINT,\n",
    "    batch_size=32,\n",
    "    max_seq_len=101,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.06,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_COMET_PIQA_CHECKPOINT = \"\"\n",
    "\n",
    "bart = BARTForPIQA.load_from_checkpoint(\n",
    "    PATH_TO_COMET_PIQA_CHECKPOINT,\n",
    "    hparams=hparams,\n",
    "    data_path=os.path.join(\"..\", \"data\", \"PIQA\"),\n",
    "    epochs=10,\n",
    "    lr_schedule=None,\n",
    "    num_classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = bart.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "piqa_dirty = (piqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (piqa_dirty_hits[\"ccnews_hits\"] > 0) | (piqa_dirty_hits[\"openwebtext_hits\"] > 0) | (piqa_dirty_hits[\"stories_hits\"] > 0) | (piqa_dirty_hits[\"wikipedia_hits\"] > 0) | (piqa_dirty_hits[\"atomic_hits\"] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  18,   22,   29,   47,   68,   82,   85,   87,   96,  107,  135,\n",
       "        139,  142,  147,  152,  157,  159,  164,  167,  199,  200,  216,\n",
       "        220,  223,  227,  233,  237,  239,  242,  244,  247,  254,  264,\n",
       "        267,  273,  274,  275,  276,  278,  282,  283,  292,  306,  313,\n",
       "        314,  318,  337,  346,  354,  361,  362,  363,  373,  374,  393,\n",
       "        414,  425,  430,  431,  437,  443,  470,  474,  480,  485,  513,\n",
       "        514,  518,  522,  544,  546,  553,  562,  569,  581,  587,  590,\n",
       "        596,  639,  641,  648,  650,  654,  679,  692,  702,  703,  705,\n",
       "        710,  712,  717,  735,  738,  743,  745,  746,  747,  768,  772,\n",
       "        782,  786,  800,  828,  831,  835,  849,  852,  858,  860,  861,\n",
       "        870,  871,  880,  886,  891,  920,  922,  928,  936,  939,  944,\n",
       "        946,  956,  962,  969,  976,  985,  987,  990,  997, 1010, 1013,\n",
       "       1027, 1037, 1046, 1054, 1057, 1066, 1078, 1085, 1086, 1097, 1099,\n",
       "       1105, 1112, 1119, 1127, 1138, 1157, 1161, 1169, 1171, 1176, 1177,\n",
       "       1190, 1193, 1202, 1205, 1214, 1217, 1219, 1226, 1230, 1252, 1260,\n",
       "       1270, 1276, 1282, 1286, 1287, 1294, 1295, 1304, 1330, 1339, 1341,\n",
       "       1345, 1353, 1358, 1360, 1361, 1376, 1378, 1384, 1389, 1405, 1432,\n",
       "       1433, 1451, 1453, 1460, 1461, 1465, 1468, 1475, 1479, 1480, 1489,\n",
       "       1490, 1495, 1501, 1511, 1530, 1543, 1554, 1565, 1569, 1573, 1584,\n",
       "       1592, 1595, 1597, 1614, 1617, 1619, 1622, 1632, 1634, 1638, 1644,\n",
       "       1657, 1661, 1662, 1665, 1667, 1672, 1674, 1683, 1705, 1708, 1715,\n",
       "       1717, 1725, 1736, 1742, 1750, 1777, 1791, 1801, 1812, 1817, 1825,\n",
       "       1833])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piqa_dirty_idxs = np.nonzero(piqa_dirty.values)[0]\n",
    "piqa_dirty_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "piqa_clean_idxs = np.nonzero(~piqa_dirty.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14501/14501 [00:10<00:00, 1330.97it/s]\n",
      "100%|██████████| 1612/1612 [00:01<00:00, 1405.21it/s]\n",
      "100%|██████████| 1838/1838 [00:01<00:00, 1412.02it/s]\n"
     ]
    }
   ],
   "source": [
    "bart.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "b_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    while b_idx * 32 < len(bart.test_data):\n",
    "        input_ids, attention_mask, y = bart.test_data[b_idx * 32: b_idx * 32 + 32]\n",
    "        input_ids, attention_mask = input_ids.cuda(), attention_mask.cuda()\n",
    "        ys = bart(input_ids, attention_mask)[0].cpu()\n",
    "        input_ids, attention_mask = input_ids.cpu(), attention_mask.cpu()\n",
    "        y_pred.extend(ys.cpu().tolist())\n",
    "        y_true.extend(y.tolist())\n",
    "        b_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8189300411522634"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[piqa_dirty_idxs], y_pred[piqa_dirty_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7899686520376176"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[piqa_clean_idxs], y_pred[piqa_clean_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = bart.cpu()\n",
    "del bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMET(BART) ARC Influence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BARTForARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    learning_rate=1e-3,\n",
    "    gradient_accumulation_steps=0,\n",
    "    seed=42,\n",
    "    model_name=\"facebook/bart-large\",\n",
    "    pretrained_weights=PATH_COMET_PRETRAIN_CHECKPOINT,\n",
    "    batch_size=32,\n",
    "    max_seq_len=91,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.06,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_COMET_ARC_CHECKPOINT = \"\"\n",
    "\n",
    "bart = BARTForARC.load_from_checkpoint(\n",
    "    PATH_TO_COMET_ARC_CHECKPOINT,\n",
    "    hparams=hparams,\n",
    "    data_path=None,\n",
    "    epochs=10,\n",
    "    lr_schedule=None,\n",
    "    num_classes=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = bart.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_dirty = (arc_dirty_hits[\"BookCorpus_hits\"] > 0) | (arc_dirty_hits[\"ccnews_hits\"] > 0) | (arc_dirty_hits[\"openwebtext_hits\"] > 0) | (arc_dirty_hits[\"stories_hits\"] > 0) | (arc_dirty_hits[\"wikipedia_hits\"] > 0) | (arc_dirty_hits[\"atomic_hits\"] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_dirty_idxs = np.nonzero(arc_dirty.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_clean_idxs = np.nonzero(~arc_dirty.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1119/1119 [00:01<00:00, 569.51it/s]\n",
      "100%|██████████| 299/299 [00:00<00:00, 635.63it/s]\n",
      "100%|██████████| 1172/1172 [00:01<00:00, 664.60it/s]\n"
     ]
    }
   ],
   "source": [
    "bart.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "b_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    while b_idx * 32 < len(bart.test_data):\n",
    "        input_ids, attention_mask, y = bart.test_data[b_idx * 32: b_idx * 32 + 32]\n",
    "        input_ids, attention_mask = input_ids.cuda(), attention_mask.cuda()\n",
    "        ys = bart(input_ids, attention_mask)[0].cpu()\n",
    "        input_ids, attention_mask = input_ids.cpu(), attention_mask.cpu()\n",
    "        y_pred.extend(ys.cpu().tolist())\n",
    "        y_true.extend(y.tolist())\n",
    "        b_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428571428571429"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[arc_dirty_idxs], y_pred[arc_dirty_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41968911917098445"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[arc_clean_idxs], y_pred[arc_clean_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = bart.cpu()\n",
    "del bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMET(BART) CSQA Influence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BARTForCSQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    learning_rate=1e-3,\n",
    "    gradient_accumulation_steps=0,\n",
    "    seed=42,\n",
    "    model_name=\"facebook/bart-large\",\n",
    "    pretrained_weights=PATH_COMET_PRETRAIN_CHECKPOINT,\n",
    "    batch_size=32,\n",
    "    max_seq_len=88,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.06,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_COMET_CSQA_CHECKPOINT = \"\"\n",
    "\n",
    "bart = BARTForCSQA.load_from_checkpoint(\n",
    "    PATH_TO_COMET_CSQA_CHECKPOINT,\n",
    "    hparams=hparams,\n",
    "    data_path=None,\n",
    "    epochs=10,\n",
    "    lr_schedule=None,\n",
    "    num_classes=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = bart.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "csqa_dirty = (csqa_dirty_hits[\"BookCorpus_hits\"] > 0) | (csqa_dirty_hits[\"ccnews_hits\"] > 0) | (csqa_dirty_hits[\"openwebtext_hits\"] > 0) | (csqa_dirty_hits[\"stories_hits\"] > 0) | (csqa_dirty_hits[\"wikipedia_hits\"] > 0) | (csqa_dirty_hits[\"atomic_hits\"] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "csqa_dirty_idxs = np.nonzero(csqa_dirty.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "csqa_clean_idxs = np.nonzero(~csqa_dirty.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8766/8766 [00:11<00:00, 777.38it/s]\n",
      "100%|██████████| 975/975 [00:01<00:00, 802.78it/s]\n",
      "100%|██████████| 1221/1221 [00:01<00:00, 768.01it/s]\n"
     ]
    }
   ],
   "source": [
    "bart.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "b_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    while b_idx * 32 < len(bart.test_data):\n",
    "        input_ids, attention_mask, y = bart.test_data[b_idx * 32: b_idx * 32 + 32]\n",
    "        input_ids, attention_mask = input_ids.cuda(), attention_mask.cuda()\n",
    "        ys = bart(input_ids, attention_mask)[0].cpu()\n",
    "        input_ids, attention_mask = input_ids.cpu(), attention_mask.cpu()\n",
    "        y_pred.extend(ys.cpu().tolist())\n",
    "        y_true.extend(y.tolist())\n",
    "        b_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7096774193548387"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[csqa_dirty_idxs], y_pred[csqa_dirty_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.727351164797239"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true[csqa_clean_idxs], y_pred[csqa_clean_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARC\n",
    "ds = load_dataset(\"ai2_arc\", \"ARC-Challenge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "0: Occurrences=239 Percentage=0.214\n",
      "1: Occurrences=296 Percentage=0.265\n",
      "2: Occurrences=291 Percentage=0.26\n",
      "3: Occurrences=293 Percentage=0.262\n",
      "\n",
      "test\n",
      "0: Occurrences=266 Percentage=0.227\n",
      "1: Occurrences=311 Percentage=0.265\n",
      "2: Occurrences=310 Percentage=0.265\n",
      "3: Occurrences=285 Percentage=0.243\n",
      "\n",
      "validation\n",
      "0: Occurrences=64 Percentage=0.214\n",
      "1: Occurrences=73 Percentage=0.244\n",
      "2: Occurrences=78 Percentage=0.261\n",
      "3: Occurrences=83 Percentage=0.278\n",
      "4: Occurrences=1 Percentage=0.003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in ds:\n",
    "    count = Counter()\n",
    "    for ex in ds[split]:\n",
    "        count[ex[\"choices\"][\"label\"].index(ex['answerKey'])] += 1\n",
    "    counts = sorted(count.most_common(), key=lambda x: x[0])\n",
    "    print(split)\n",
    "    for answ_n, occurrences in counts:\n",
    "        print(f\"{answ_n}:\", f\"Occurrences={occurrences}\", f\"Percentage={round(occurrences / len(ds[split]), 3)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSQA\n",
    "ds = load_dataset(\"commonsense_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "0: Occurrences=1909 Percentage=0.196\n",
      "1: Occurrences=1973 Percentage=0.203\n",
      "2: Occurrences=1946 Percentage=0.2\n",
      "3: Occurrences=1985 Percentage=0.204\n",
      "4: Occurrences=1928 Percentage=0.198\n",
      "\n",
      "validation\n",
      "0: Occurrences=239 Percentage=0.196\n",
      "1: Occurrences=255 Percentage=0.209\n",
      "2: Occurrences=241 Percentage=0.197\n",
      "3: Occurrences=251 Percentage=0.206\n",
      "4: Occurrences=235 Percentage=0.192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in filter(lambda x: x != \"test\", ds):\n",
    "    count = Counter()\n",
    "    for ex in ds[split]:\n",
    "        count[ex[\"choices\"][\"label\"].index(ex['answerKey'])] += 1\n",
    "    counts = sorted(count.most_common(), key=lambda x: x[0])\n",
    "    print(split)\n",
    "    for answ_n, occurrences in counts:\n",
    "        print(f\"{answ_n}:\", f\"Occurrences={occurrences}\", f\"Percentage={round(occurrences / len(ds[split]), 3)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCT\n",
    "train = list(map(lambda x: x[1], pd.read_csv(os.path.join(\"..\", \"data\", \"arct\", \"train.csv\"), sep=\"\\t\").iterrows()))\n",
    "dev = list(map(lambda x: x[1], pd.read_csv(os.path.join(\"..\", \"data\", \"arct\", \"dev.csv\"), sep=\"\\t\").iterrows()))\n",
    "test = list(map(lambda x: x[1], pd.read_csv(os.path.join(\"..\", \"data\", \"arct\", \"test.csv\"), sep=\"\\t\").iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "0: Occurrences=1210 Percentage=0.5\n",
      "1: Occurrences=1210 Percentage=0.5\n",
      "\n",
      "dev\n",
      "0: Occurrences=316 Percentage=0.5\n",
      "1: Occurrences=316 Percentage=0.5\n",
      "\n",
      "test\n",
      "0: Occurrences=444 Percentage=0.5\n",
      "1: Occurrences=444 Percentage=0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split, df in [(\"train\", train), (\"dev\", dev), (\"test\", test)]:\n",
    "    count = Counter()\n",
    "    for ex in df:\n",
    "        count[ex[\"correctLabelW0orW1\"]] += 1\n",
    "    counts = sorted(count.most_common(), key=lambda x: x[0])\n",
    "    print(split)\n",
    "    for answ_n, occurrences in counts:\n",
    "        print(f\"{answ_n}:\", f\"Occurrences={occurrences}\", f\"Percentage={round(occurrences / len(df), 3)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIQA\n",
    "with open(os.path.join(\"..\", \"data\", \"PIQA\", \"train-labels.lst\")) as fr:\n",
    "    train = list(map(lambda x: int(x), fr))\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", \"PIQA\", \"valid-labels.lst\")) as fr:\n",
    "    dev = list(map(lambda x: int(x), fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "0: Occurrences=8053 Percentage=0.5\n",
      "1: Occurrences=8060 Percentage=0.5\n",
      "\n",
      "dev\n",
      "0: Occurrences=910 Percentage=0.495\n",
      "1: Occurrences=928 Percentage=0.505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split, df in [(\"train\", train), (\"dev\", dev)]:\n",
    "    count = Counter()\n",
    "    for ex in df:\n",
    "        count[ex] += 1\n",
    "    counts = sorted(count.most_common(), key=lambda x: x[0])\n",
    "    print(split)\n",
    "    for answ_n, occurrences in counts:\n",
    "        print(f\"{answ_n}:\", f\"Occurrences={occurrences}\", f\"Percentage={round(occurrences / len(df), 3)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Cue (Niven style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cue_metrics(exs, n):\n",
    "    counters = defaultdict(Counter)\n",
    "    \n",
    "    for ex in exs:\n",
    "        choices_ngrams = [\n",
    "            set(ngrams(tokenize(choice), n))\n",
    "            for choice in ex[\"choices\"]\n",
    "        ]\n",
    "        for i, choice in enumerate(choices_ngrams):\n",
    "            diff = choice.difference(reduce(lambda acc, x: acc.union(x), choices_ngrams[:i] + choices_ngrams[i + 1:], set()))\n",
    "            for cue in diff:\n",
    "                counters[\"applicability\"][cue] += 1\n",
    "                if i == ex[\"target\"]:\n",
    "                    counters[\"applicability_right\"][cue] += 1\n",
    "    \n",
    "    for cue in counters[\"applicability\"]:\n",
    "        counters[\"productivity\"][cue] =  counters[\"applicability_right\"][cue] / counters[\"applicability\"][cue]\n",
    "        counters[\"coverage\"][cue] = counters[\"applicability\"][cue] / len(exs)\n",
    "    \n",
    "    return counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARC\n",
    "\n",
    "ds = load_dataset(\"ai2_arc\", \"ARC-Challenge\")\n",
    "metrics_uni = calculate_cue_metrics(\n",
    "    [\n",
    "        {\"choices\": ex[\"choices\"][\"text\"], \"target\": ex[\"choices\"][\"label\"].index(ex[\"answerKey\"])}\n",
    "        for split_ds in [ds[\"train\"], ds[\"validation\"], ds[\"test\"]]\n",
    "        for ex in split_ds\n",
    "    ],\n",
    "    1\n",
    ")\n",
    "metrics_bi = calculate_cue_metrics(\n",
    "    [\n",
    "        {\"choices\": ex[\"choices\"][\"text\"], \"target\": ex[\"choices\"][\"label\"].index(ex[\"answerKey\"])}\n",
    "        for split_ds in [ds[\"train\"], ds[\"validation\"], ds[\"test\"]]\n",
    "        for ex in split_ds\n",
    "    ],\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('to',) 0.13281853281853281 0.25872093023255816 useful=True\n",
      "('in',) 0.12664092664092663 0.25 useful=False\n",
      "('of',) 0.12625482625482626 0.24770642201834864 useful=False\n",
      "('a',) 0.10926640926640926 0.2226148409893993 useful=False\n",
      "('the',) 0.09266409266409266 0.24583333333333332 useful=False\n",
      "('water',) 0.0918918918918919 0.15126050420168066 useful=False\n",
      "('from',) 0.0694980694980695 0.22777777777777777 useful=False\n",
      "('and',) 0.06254826254826255 0.4074074074074074 useful=True\n",
      "('on',) 0.062162162162162166 0.2608695652173913 useful=True\n",
      "('for',) 0.05328185328185328 0.2898550724637681 useful=True\n",
      "('an',) 0.04903474903474903 0.29133858267716534 useful=True\n",
      "('more',) 0.04749034749034749 0.17073170731707318 useful=False\n",
      "('is',) 0.044787644787644784 0.16379310344827586 useful=False\n",
      "('food',) 0.04247104247104247 0.35454545454545455 useful=True\n",
      "('are',) 0.040926640926640924 0.3018867924528302 useful=True\n",
      "('energy',) 0.040926640926640924 0.2358490566037736 useful=False\n",
      "('with',) 0.04054054054054054 0.20952380952380953 useful=False\n",
      "('by',) 0.039382239382239385 0.28431372549019607 useful=True\n",
      "('into',) 0.039382239382239385 0.28431372549019607 useful=True\n",
      "('air',) 0.03667953667953668 0.3473684210526316 useful=True\n",
      "('at',) 0.036293436293436294 0.24468085106382978 useful=False\n",
      "('heat',) 0.032818532818532815 0.27058823529411763 useful=True\n",
      "('oxygen',) 0.032818532818532815 0.25882352941176473 useful=True\n",
      "('that',) 0.03127413127413128 0.2962962962962963 useful=True\n",
      "('be',) 0.03127413127413128 0.2345679012345679 useful=False\n"
     ]
    }
   ],
   "source": [
    "for cue, coverage in metrics_uni[\"coverage\"].most_common(25):\n",
    "    print(cue, coverage, metrics_uni[\"productivity\"][cue], f\"useful={metrics_uni['productivity'][cue] > 1/4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('of', 'the') 0.06525096525096526 0.15384615384615385 useful=False\n",
      "('in', 'the') 0.06332046332046332 0.24390243902439024 useful=False\n",
      "('to', 'the') 0.03513513513513514 0.24175824175824176 useful=False\n",
      "('amount', 'of') 0.029343629343629343 0.25 useful=False\n",
      "('from', 'the') 0.027413127413127413 0.2676056338028169 useful=False\n",
      "('in', 'a') 0.02702702702702703 0.3 useful=False\n",
      "('on', 'the') 0.025096525096525095 0.2153846153846154 useful=False\n",
      "('the', 'same') 0.021621621621621623 0.30357142857142855 useful=False\n",
      "('number', 'of') 0.021235521235521235 0.16363636363636364 useful=False\n",
      "('the', 'amount') 0.019691119691119693 0.23529411764705882 useful=False\n",
      "('of', 'a') 0.018532818532818532 0.25 useful=False\n",
      "('the', 'sun') 0.01776061776061776 0.391304347826087 useful=False\n",
      "('carbon', 'dioxide') 0.015057915057915058 0.07692307692307693 useful=False\n",
      "('into', 'the') 0.013513513513513514 0.2571428571428571 useful=False\n",
      "('of', 'water') 0.013513513513513514 0.17142857142857143 useful=False\n",
      "('type', 'of') 0.013127413127413128 0.23529411764705882 useful=False\n",
      "('mass', 'of') 0.012741312741312742 0.24242424242424243 useful=False\n",
      "('the', 'water') 0.012741312741312742 0.09090909090909091 useful=False\n",
      "('the', 'air') 0.012741312741312742 0.2727272727272727 useful=False\n",
      "('at', 'the') 0.012355212355212355 0.21875 useful=False\n",
      "('to', 'be') 0.011583011583011582 0.13333333333333333 useful=False\n",
      "('types', 'of') 0.010038610038610039 0.2692307692307692 useful=False\n",
      "('on', 'a') 0.010038610038610039 0.2692307692307692 useful=False\n",
      "('the', 'moon') 0.010038610038610039 0.07692307692307693 useful=False\n",
      "('the', 'number') 0.009652509652509652 0.28 useful=False\n"
     ]
    }
   ],
   "source": [
    "for cue, coverage in metrics_bi[\"coverage\"].most_common(25):\n",
    "    print(cue, coverage, metrics_bi[\"productivity\"][cue], f\"useful={metrics_uni['productivity'][cue] > 1/4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSQA\n",
    "\n",
    "ds = load_dataset(\"commonsense_qa\")\n",
    "metrics_uni = calculate_cue_metrics(\n",
    "    [\n",
    "        {\"choices\": ex[\"choices\"][\"text\"], \"target\": ex[\"choices\"][\"label\"].index(ex[\"answerKey\"])}\n",
    "        for split_ds in [ds[\"train\"], ds[\"validation\"]]\n",
    "        for ex in split_ds\n",
    "    ],\n",
    "    1\n",
    ")\n",
    "metrics_bi = calculate_cue_metrics(\n",
    "    [\n",
    "        {\"choices\": ex[\"choices\"][\"text\"], \"target\": ex[\"choices\"][\"label\"].index(ex[\"answerKey\"])}\n",
    "        for split_ds in [ds[\"train\"], ds[\"validation\"]]\n",
    "        for ex in split_ds\n",
    "    ],\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('store',) 0.0652253238460135 0.23636363636363636 useful=True\n",
      "('house',) 0.06139390622149243 0.1887072808320951 useful=False\n",
      "('to',) 0.05966064586754242 0.16666666666666666 useful=False\n",
      "('of',) 0.059295748950921365 0.19384615384615383 useful=False\n",
      "('in',) 0.045064769202700236 0.1214574898785425 useful=False\n",
      "('office',) 0.034026637474913336 0.225201072386059 useful=True\n",
      "('city',) 0.03357051632913702 0.22010869565217392 useful=True\n",
      "('room',) 0.03247582557927386 0.22752808988764045 useful=True\n",
      "('school',) 0.03229337712096333 0.1864406779661017 useful=False\n",
      "('get',) 0.031472359058565956 0.22608695652173913 useful=True\n",
      "('park',) 0.029556650246305417 0.16049382716049382 useful=False\n",
      "('home',) 0.028188286808976466 0.20064724919093851 useful=True\n",
      "('building',) 0.0280970625798212 0.22727272727272727 useful=True\n",
      "('the',) 0.026637474913336984 0.0 useful=False\n",
      "('go',) 0.026455026455026454 0.2 useful=False\n",
      "('have',) 0.025725232621784347 0.24113475177304963 useful=True\n",
      "('new',) 0.025451559934318555 0.25089605734767023 useful=True\n",
      "('a',) 0.025177887246852763 0.0 useful=False\n",
      "('water',) 0.0230797299762817 0.2450592885375494 useful=True\n",
      "('down',) 0.02280605728881591 0.212 useful=True\n",
      "('being',) 0.022532384601350118 0.25101214574898784 useful=True\n",
      "('shop',) 0.021437693851486955 0.19574468085106383 useful=False\n",
      "('kitchen',) 0.021164021164021163 0.15948275862068967 useful=False\n",
      "('restaurant',) 0.020616675789089583 0.2079646017699115 useful=True\n",
      "('food',) 0.020434227330779056 0.19196428571428573 useful=False\n"
     ]
    }
   ],
   "source": [
    "for cue, coverage in metrics_uni[\"coverage\"].most_common(25):\n",
    "    print(cue, coverage, metrics_uni[\"productivity\"][cue], f\"useful={metrics_uni['productivity'][cue] > 1/5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('go', 'to') 0.012406495165115855 0.19852941176470587 useful=False\n",
      "('new', 'york') 0.01076445904032111 0.211864406779661 useful=True\n",
      "('grocery', 'store') 0.010490786352855318 0.2 useful=False\n",
      "('have', 'fun') 0.00875752599890531 0.25 useful=True\n",
      "('talk', 'to') 0.007754059478197409 0.058823529411764705 useful=False\n",
      "('office', 'building') 0.007662835249042145 0.25 useful=True\n",
      "('friend', 'house') 0.007571611019886882 0.26506024096385544 useful=True\n",
      "('each', 'other') 0.007571611019886882 0.0963855421686747 useful=False\n",
      "('neighbor', 'house') 0.0074803867907316185 0.2804878048780488 useful=True\n",
      "('living', 'room') 0.007297938332421091 0.1875 useful=False\n",
      "('music', 'store') 0.007297938332421091 0.3375 useful=True\n",
      "('of', 'earth') 0.007297938332421091 0.2125 useful=True\n",
      "('surface', 'of') 0.007297938332421091 0.2125 useful=True\n",
      "('united', 'states') 0.006933041415800037 0.2631578947368421 useful=True\n",
      "('own', 'home') 0.006933041415800037 0.25 useful=True\n",
      "('train', 'station') 0.006750592957489509 0.22972972972972974 useful=True\n",
      "('toy', 'store') 0.006659368728334246 0.2602739726027397 useful=True\n",
      "('to', 'each') 0.006568144499178982 0.027777777777777776 useful=False\n",
      "('believe', 'in') 0.006476920270023718 0.04225352112676056 useful=False\n",
      "('own', 'house') 0.006385696040868455 0.1 useful=False\n",
      "('space', 'shuttle') 0.006385696040868455 0.2571428571428571 useful=True\n",
      "('hardware', 'store') 0.006294471811713191 0.2463768115942029 useful=True\n",
      "('in', 'god') 0.0062032475825579275 0.058823529411764705 useful=False\n",
      "('to', 'jail') 0.006112023353402663 0.19402985074626866 useful=False\n",
      "('department', 'store') 0.006112023353402663 0.2537313432835821 useful=True\n"
     ]
    }
   ],
   "source": [
    "for cue, coverage in metrics_bi[\"coverage\"].most_common(25):\n",
    "    print(cue, coverage, metrics_bi[\"productivity\"][cue], f\"useful={metrics_bi['productivity'][cue] > 1/5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCT\n",
    "\n",
    "ds = list(map(lambda x: x[1], pd.read_csv(os.path.join(\"..\", \"data\", \"arct\", \"train.csv\"), sep=\"\\t\").iterrows())) + \\\n",
    "    list(map(lambda x: x[1], pd.read_csv(os.path.join(\"..\", \"data\", \"arct\", \"dev.csv\"), sep=\"\\t\").iterrows())) + \\\n",
    "    list(map(lambda x: x[1], pd.read_csv(os.path.join(\"..\", \"data\", \"arct\", \"test.csv\"), sep=\"\\t\").iterrows()))\n",
    "\n",
    "metrics_uni = calculate_cue_metrics(\n",
    "    [\n",
    "        {\"choices\": [ex[\"warrant0\"], ex[\"warrant1\"]], \"target\": ex[\"correctLabelW0orW1\"]}\n",
    "        for ex in ds\n",
    "    ],\n",
    "    1\n",
    ")\n",
    "metrics_bi = calculate_cue_metrics(\n",
    "    [\n",
    "        {\"choices\": [ex[\"warrant0\"], ex[\"warrant1\"]], \"target\": ex[\"correctLabelW0orW1\"]}\n",
    "        for ex in ds\n",
    "    ],\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('not',) 0.3766497461928934 0.5 useful=False\n",
      "('do',) 0.11776649746192894 0.5 useful=False\n",
      "('does',) 0.062436548223350256 0.5 useful=False\n",
      "('can',) 0.06142131979695432 0.5 useful=False\n",
      "('to',) 0.05583756345177665 0.5 useful=False\n",
      "('and',) 0.04517766497461929 0.5 useful=False\n",
      "('no',) 0.04314720812182741 0.5 useful=False\n",
      "('a',) 0.04010152284263959 0.5 useful=False\n",
      "('ca',) 0.03654822335025381 0.5 useful=False\n",
      "('be',) 0.0350253807106599 0.5 useful=False\n",
      "('more',) 0.03451776649746193 0.5 useful=False\n",
      "('is',) 0.03299492385786802 0.5 useful=False\n",
      "('are',) 0.03299492385786802 0.5 useful=False\n",
      "('will',) 0.029949238578680204 0.5 useful=False\n",
      "('of',) 0.028426395939086295 0.5 useful=False\n",
      "('have',) 0.027918781725888325 0.5 useful=False\n",
      "('should',) 0.027411167512690356 0.5 useful=False\n",
      "('the',) 0.026903553299492386 0.5 useful=False\n",
      "('wo',) 0.024873096446700507 0.5 useful=False\n",
      "('only',) 0.023857868020304568 0.5 useful=False\n",
      "('still',) 0.02182741116751269 0.5 useful=False\n",
      "('even',) 0.02131979695431472 0.5 useful=False\n",
      "('need',) 0.02030456852791878 0.5 useful=False\n",
      "('less',) 0.01979695431472081 0.5 useful=False\n",
      "('many',) 0.019289340101522844 0.5 useful=False\n"
     ]
    }
   ],
   "source": [
    "for cue, coverage in metrics_uni[\"coverage\"].most_common(25):\n",
    "    print(cue, coverage, metrics_uni[\"productivity\"][cue], f\"useful={metrics_uni['productivity'][cue] > 1/2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('is', 'not') 0.09035532994923857 0.5 useful=False\n",
      "('are', 'not') 0.06802030456852792 0.5 useful=False\n",
      "('do', 'not') 0.04365482233502538 0.5 useful=False\n",
      "('can', 'not') 0.03248730964467005 0.5 useful=False\n",
      "('does', 'not') 0.030456852791878174 0.5 useful=False\n",
      "('not', 'be') 0.028934010152284265 0.5 useful=False\n",
      "('is', 'a') 0.025888324873096447 0.5 useful=False\n",
      "('can', 'be') 0.024365482233502538 0.5 useful=False\n",
      "('will', 'not') 0.023350253807106598 0.5 useful=False\n",
      "('not', 'a') 0.02081218274111675 0.5 useful=False\n",
      "('to', 'be') 0.016751269035532996 0.5 useful=False\n",
      "('should', 'be') 0.016243654822335026 0.5 useful=False\n",
      "('not', 'have') 0.015228426395939087 0.5 useful=False\n",
      "('people', 'do') 0.014720812182741117 0.5 useful=False\n",
      "('should', 'not') 0.014720812182741117 0.5 useful=False\n",
      "('they', 'do') 0.013197969543147208 0.5 useful=False\n",
      "('need', 'to') 0.012690355329949238 0.5 useful=False\n",
      "('do', 'need') 0.012690355329949238 0.5 useful=False\n",
      "('not', 'the') 0.011675126903553299 0.5 useful=False\n",
      "('would', 'not') 0.011675126903553299 0.5 useful=False\n",
      "('we', 'do') 0.01116751269035533 0.5 useful=False\n",
      "('not', 'always') 0.01116751269035533 0.5 useful=False\n",
      "('do', 'have') 0.01065989847715736 0.5 useful=False\n",
      "('not', 'need') 0.009644670050761422 0.5 useful=False\n",
      "('and', 'not') 0.009644670050761422 0.5 useful=False\n"
     ]
    }
   ],
   "source": [
    "for cue, coverage in metrics_bi[\"coverage\"].most_common(25):\n",
    "    print(cue, coverage, metrics_bi[\"productivity\"][cue], f\"useful={metrics_bi['productivity'][cue] > 1/2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIQA\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", \"PIQA\", \"train-labels.lst\")) as fr:\n",
    "    train_y = list(map(lambda x: int(x), fr))\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", \"PIQA\", \"valid-labels.lst\")) as fr:\n",
    "    dev_y = list(map(lambda x: int(x), fr))\n",
    "    \n",
    "with open(os.path.join(\"..\", \"data\", \"PIQA\", \"valid.jsonl\")) as fr:\n",
    "    dev_x = list(map(lambda line: json.loads(line), fr))\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", \"PIQA\", \"train.jsonl\")) as fr:\n",
    "    train_x = list(map(lambda line: json.loads(line), fr))\n",
    "    \n",
    "ds = list(zip(train_x, train_y)) + list(zip(dev_x, dev_y))\n",
    "\n",
    "metrics_uni = calculate_cue_metrics(\n",
    "    [\n",
    "        {\"choices\": [ex[0][\"sol1\"], ex[0][\"sol2\"]], \"target\": ex[1]}\n",
    "        for ex in ds\n",
    "    ],\n",
    "    1\n",
    ")\n",
    "metrics_bi = calculate_cue_metrics(\n",
    "    [\n",
    "        {\"choices\": [ex[0][\"sol1\"], ex[0][\"sol2\"]], \"target\": ex[1]}\n",
    "        for ex in ds\n",
    "    ],\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a',) 0.09587209626204668 0.5235328297501453 useful=True\n",
      "('of',) 0.07275360704139046 0.49617151607963245 useful=False\n",
      "('to',) 0.06545596345607486 0.49361702127659574 useful=False\n",
      "('and',) 0.06540025625313353 0.524701873935264 useful=True\n",
      "('in',) 0.06428611219430673 0.46707105719237435 useful=False\n",
      "('on',) 0.061389337641357025 0.5254083484573503 useful=True\n",
      "('the',) 0.05453735167957217 0.39938712972420837 useful=False\n",
      "('with',) 0.05197482034427051 0.4705251875669882 useful=False\n",
      "('it',) 0.04746253690602195 0.4753521126760563 useful=False\n",
      "('water',) 0.04194752381482926 0.5232403718459495 useful=True\n",
      "('your',) 0.03737953317363935 0.45007451564828616 useful=False\n",
      "('for',) 0.03153027686479862 0.450530035335689 useful=False\n",
      "('you',) 0.028689209514790263 0.45048543689320386 useful=False\n",
      "('paper',) 0.027129407832432735 0.46611909650924027 useful=False\n",
      "('use',) 0.02612667817948861 0.5501066098081023 useful=True\n",
      "('an',) 0.02612667817948861 0.5543710021321961 useful=True\n",
      "('up',) 0.025402484541251182 0.46271929824561403 useful=False\n",
      "('then',) 0.02517965572948582 0.4778761061946903 useful=False\n",
      "('out',) 0.025068241323603142 0.5266666666666666 useful=True\n",
      "('into',) 0.02439975488830706 0.5182648401826484 useful=True\n",
      "('top',) 0.02245000278536015 0.47890818858560796 useful=False\n",
      "('from',) 0.02105732271182664 0.4708994708994709 useful=False\n",
      "('is',) 0.020723079494178596 0.4731182795698925 useful=False\n",
      "('over',) 0.020611665088295917 0.5243243243243243 useful=True\n",
      "('put',) 0.020500250682413235 0.43478260869565216 useful=False\n"
     ]
    }
   ],
   "source": [
    "for cue, coverage in metrics_uni[\"coverage\"].most_common(25):\n",
    "    print(cue, coverage, metrics_uni[\"productivity\"][cue], f\"useful={metrics_uni['productivity'][cue] > 1/2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('in', 'the') 0.03197593448832934 0.4146341463414634 useful=False\n",
      "('on', 'the') 0.028912038326555624 0.5375722543352601 useful=True\n",
      "('of', 'the') 0.02835496629714222 0.5029469548133595 useful=True\n",
      "('with', 'a') 0.025681020555957886 0.46637744034707157 useful=False\n",
      "('use', 'a') 0.022505709988301488 0.5123762376237624 useful=True\n",
      "('to', 'the') 0.020110300261823855 0.46814404432132967 useful=False\n",
      "('in', 'a') 0.0175477689265222 0.5015873015873016 useful=True\n",
      "('and', 'then') 0.01604367444710601 0.4270833333333333 useful=False\n",
      "('into', 'the') 0.013648264720628377 0.5224489795918368 useful=True\n",
      "('top', 'of') 0.013314021502980335 0.4476987447698745 useful=False\n",
      "('the', 'top') 0.013258314300038996 0.47478991596638653 useful=False\n",
      "('on', 'a') 0.01075149016767868 0.5699481865284974 useful=True\n",
      "('the', 'bottom') 0.010472954152971978 0.526595744680851 useful=True\n",
      "('from', 'the') 0.010417246950030639 0.4385026737967914 useful=False\n",
      "('water', 'and') 0.009525931702969195 0.5497076023391813 useful=True\n",
      "('it', 'in') 0.009247395688262492 0.41566265060240964 useful=False\n",
      "('of', 'a') 0.009135981282379812 0.5121951219512195 useful=True\n",
      "('you', 'can') 0.008634616455907749 0.43870967741935485 useful=False\n",
      "('over', 'the') 0.008021837223553005 0.5138888888888888 useful=True\n",
      "('with', 'the') 0.008021837223553005 0.4166666666666667 useful=False\n",
      "('of', 'water') 0.007966130020611665 0.5874125874125874 useful=True\n",
      "('bottom', 'of') 0.007687594005904964 0.5072463768115942 useful=True\n",
      "('of', 'your') 0.007520472397080942 0.5259259259259259 useful=True\n",
      "('cold', 'water') 0.007297643585315581 0.4732824427480916 useful=False\n",
      "('for', 'a') 0.007297643585315581 0.5190839694656488 useful=True\n"
     ]
    }
   ],
   "source": [
    "for cue, coverage in metrics_bi[\"coverage\"].most_common(25):\n",
    "    print(cue, coverage, metrics_bi[\"productivity\"][cue], f\"useful={metrics_bi['productivity'][cue] > 1/2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
